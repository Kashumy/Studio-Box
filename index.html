<!DOCTYPE html>
<html lang="en" ondblclick="document.documentElement.requestFullscreen()">
<head>


    <link rel="icon" type="image/png" sizes="192x192" href="./favico.png">
 
    <script   src="./lame.min.js" defer></script>
    <script src="./jquery-3.4.1.min.js" defer></script>
    <link href="./select2.min.css" rel="stylesheet" />
    <script src="./select2.min.js" defer></script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="./jszip.min.js" type="text/javascript" charset="utf-8"></script>

 
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>FruityBox</title>

    <meta name="application-name" content="Fruity Box" />
    <meta name="apple-mobile-web-app-title" content="Paandora's Box">
	<meta name="description" content="FruityBox Box is an online tool for sketching and sharing your music." />
    <meta name="keywords" content="chiptune, instrumental, music, song, melody, composition, tool, free, square wave, NES, NSF, JummBox, jummbox, BeepBox, beepbox, FruityBox " />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta name="theme-color" content="#444" />
    <meta name="msapplication-TileColor" content="#603cba" />
    <meta name="msapplication-config" content="/browserconfig.xml" />
    <meta name="format-detection" content="telephone=no" />
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/icon_32.png" />
    <link rel="manifest" href="/manifest.webmanifest" />
    <link href="https://fonts.googleapis.com/css?family=B612" rel="stylesheet" media="none" onload="if (this.media != 'all') this.media='all';" /> <!-- this is a trick to load CSS asynchronously. -->
    <style type="text/css">

        html {
            background: var(--editor-background, black);
            overflow-x: hidden;
            font-size: large;
             
            font-family: 'B612', sans-serif;
            line-height: 1.3;
            color: var(--primary-text) !important;
        }
 

#plugins-content {
	margin: 0px;
	overflow-x: hidden;
	display: flex;
	flex-direction: column;
	align-items: center;
	align-content: center;
}
 
button{
 background:var(--ui-widget-background, #444);
 color:var(--primary-text, black);
 padding:4px;
 border:none; outline:none; border-radius: 5px;
 margin:1px;
}
button:disabled{
  background:color-mix(in srgb, var(--ui-widget-background, #444) 70%, black);
  color:#777;
  cursor:not-allowed;
}

input[type="number"] {
 background: var(--editor-background, black);
 color: var(--primary-text, black);
 padding: 2px;
 border: 1px solid var(--input-box-outline, black);
 border-radius: 5px;
 margin: 1px;
 width: 60px;
}
input[type="text"] {
 background: var(--editor-background, black);
 color: var(--primary-text, black);
 padding: 2px;
 border: 1px solid var(--input-box-outline, black);
 border-radius: 5px;
 margin: 1px;
 width: 60px;
}
input[type="file"]::file-selector-button {
 background: var(--ui-widget-background, #222);
 color: var(--primary-text, white);
 border: 1px solid var(--input-box-outline, black);
 border-radius: 6px;
 padding: 6px 12px;
 margin-right: 8px;
 cursor: pointer;
 transition: background 0.2s, transform 0.1s;
}

input[type="file"]::file-selector-button:hover {
 background: var(--primary-hover, #444);
}

input[type="file"]::file-selector-button:active {
 transform: scale(0.97);
}
 

select {
 background: var(--editor-background, black);
 color: var(--primary-text, black);
 padding: 4px;
 border: 2px solid var(--input-box-outline, black);
 border-radius: 5px;
 margin: 1px;
 width: 60px;
 /* opcjonalnie, ≈ºeby by≈Ço ≈Çadnie dla liczb */
}
        body {
            margin: auto;
            overflow-x: hidden;
            display: flex;
            flex-direction: column;
            align-items: center;
            align-content: center;
        }

        #beepboxEditorContainer {
            min-height: 645px;
            overflow: auto;
            background: var(--editor-background, black);
            width: 100%;
			max-width: 710px;
            padding-left: 30px;
            padding-right: 30px;
        }

        #text-content {
            overflow: auto;
            background: var(--editor-background, black);
            width: 100%;
			max-width: 710px;
            padding-left: 30px;
            padding-right: 30px;
        }

        h1 {
            font-size: 1.7rem;
            text-align: center;
            margin-top: 0.5em;
            margin-bottom: 0.5em;
            -webkit-text-stroke-width: 0;
        }

        h2 {
            font-size: 1.5rem;
            text-align: center;
            margin-top: 0.5em;
            margin-bottom: 0.5em;
            -webkit-text-stroke-width: 0;
        }

        .centerDiv {
			margin: 0px auto;
		}

        a {
            color: var(--link-accent, #98f);
        }

        .donation form {
            display: inline;
        }

        .donation input[type="submit"] {
            -webkit-appearance: none;
            background: none;
            border: none;
            font-family: inherit;
            font-size: inherit;
            color: var(--link-accent, #98f);
            text-decoration: underline;
            cursor: pointer;
            padding: 0;
            margin: 0;
        }
		
 
            .column-container {
				width: 710px;
                display: flex;
				gap: 25px;
            }

            .instructions-column {
				min-width: 0;
            }

            .twitter-column {
                width: 300px;
				flex-shrink: 0;
            }
        }

        /* narrow screen */
		@media (max-width: 710px) {
            body {
                width: 100%;
            }

            p, .donation {
                margin: 1em 0.5em;
            }

            .column-container {
                display: flex;
                flex-direction: column;
                align-items: center;
            }
        }
    </style>
</head> 
 
<script  src="./calmsounds1.js" defer></script>
<script  src="./samplesofchillsounds.js" defer></script>
<script  src="./test.js" defer></script>
<script  src="./rawsamples.js" defer></script>
<script  src="./sample1.js" defer></script>
<script  src="./mysamples.js" defer></script> 
 
 
 
 
<body>
	
	    <script>
	    
const loadingScreen = document.createElement("div");
loadingScreen.style.position = "fixed";
loadingScreen.style.inset = "0";
loadingScreen.style.background = "#222";
loadingScreen.style.color = "white";
loadingScreen.style.display = "flex";
loadingScreen.style.flexDirection = "column";
loadingScreen.style.justifyContent = "center";
loadingScreen.style.alignItems = "center";
loadingScreen.style.zIndex = "9999";
loadingScreen.style.transition = "opacity 0.6s ease-in-out";

const loadingText = document.createElement("div");
loadingText.style.fontSize = "1.2em";
loadingText.style.marginBottom = "20px";
loadingText.innerText = "Loading Editor...";

const progressBar = document.createElement("div");
progressBar.style.width = "300px";
progressBar.style.height = "10px";
progressBar.style.background = "#444";
progressBar.style.borderRadius = "1px";
progressBar.style.overflow = "hidden";

const progressFill = document.createElement("div");
progressFill.style.height = "100%";
progressFill.style.width = "0%";
progressFill.style.background = "limegreen";
progressFill.style.transition = "width 0.3s ease";

progressBar.appendChild(progressFill);
loadingScreen.appendChild(loadingText);
loadingScreen.appendChild(progressBar);
document.body.appendChild(loadingScreen);
	    
	    
let topZ = 1000;

function POPUP(x, y, title, content, framecolor = "#000080") {
	const win = document.createElement("div");
	Object.assign(win.style, {
		position: "absolute",
		left: x + "px",
		top: y + "px",
		width: "300px",
		height: "150px",
		border: `2px solid ${framecolor}`,
		background: "#e0e0e0",
		resize: "both",
		overflow: "hidden",
		boxShadow: "5px 5px 10px rgba(0,0,0,0.5)",
		minWidth: "200px",
		minHeight: "100px",
		zIndex: ++topZ,
		fontWeight: "200",
		fontFamily: "sans-serif"
	});

	const titlebar = document.createElement("div");
	Object.assign(titlebar.style, {
		background: framecolor,
		color: "#fff",
		padding: "2px 5px",
		cursor: "grab",
		display: "flex",
		fontWeight: "200",
		fontFamily: "sans-serif",
		justifyContent: "space-between",
		alignItems: "center",
		userSelect: "none"
	});

	const titleText = document.createElement("span");
	titleText.textContent = title;

	const buttons = document.createElement("div");
	const closeBtn = document.createElement("button");
	closeBtn.type = "button";
	closeBtn.className = "no-drag";
	closeBtn.innerHTML = `<svg viewBox="0 0 24 24" width="16" height="16" fill="white"><line x1="4" y1="4" x2="20" y2="20" stroke="white" stroke-width="2"/><line x1="20" y1="4" x2="4" y2="20" stroke="white" stroke-width="2"/></svg>`;
	Object.assign(closeBtn.style, {
		background: "red",
		border: "none",
		cursor: "pointer",
		width: "24px",
		height: "24px",
		padding: "0",
		display: "flex",
		justifyContent: "center",
		alignItems: "center"
	});
	closeBtn.addEventListener("mousedown", e => e.stopPropagation());
	closeBtn.addEventListener("touchstart", e => { e.stopPropagation(); }, { passive: false });
	closeBtn.addEventListener("click", () => win.remove());

	buttons.appendChild(closeBtn);
	titlebar.appendChild(titleText);
	titlebar.appendChild(buttons);

	const contentDiv = document.createElement("div");
	Object.assign(contentDiv.style, {
		padding: "10px",
		height: "calc(100% - 26px)",
		overflow: "auto"
	});
	contentDiv.innerHTML = content;

	win.appendChild(titlebar);
	win.appendChild(contentDiv);
	document.body.appendChild(win);

	let isDragging = false, offsetX = 0, offsetY = 0;

	function startDrag(e) {
		const target = e.target;
		if (target && target.closest && target.closest('.no-drag')) return;
		isDragging = true;
		const evt = e.touches ? e.touches[0] : e;
		offsetX = evt.clientX - win.offsetLeft;
		offsetY = evt.clientY - win.offsetTop;
		titlebar.style.cursor = "grabbing";
		document.body.style.overflow = "hidden";
		e.preventDefault();
	}

	function drag(e) {
		if (!isDragging) return;
		const evt = e.touches ? e.touches[0] : e;
		let newX = evt.clientX - offsetX;
		let newY = evt.clientY - offsetY;
		newX = Math.max(0, Math.min(window.innerWidth - win.offsetWidth, newX));
		newY = Math.max(0, Math.min(document.body.scrollHeight - win.offsetHeight, newY));
		win.style.left = newX + "px";
		win.style.top = newY + "px";
	}

	function endDrag() {
		isDragging = false;
		titlebar.style.cursor = "grab";
		document.body.style.overflow = "";
	}

	titlebar.addEventListener("mousedown", startDrag);
	document.addEventListener("mousemove", drag);
	document.addEventListener("mouseup", endDrag);
	titlebar.addEventListener("touchstart", startDrag, { passive: false });
	document.addEventListener("touchmove", drag, { passive: false });
	document.addEventListener("touchend", endDrag);
	win.addEventListener("mousedown", () => win.style.zIndex = ++topZ);
	win.addEventListener("touchstart", () => win.style.zIndex = ++topZ);
}


 
 

    	
    
    </script>
	
	
	
    <div id="beepboxEditorContainer">
        <noscript>
            Sorry, FruityBox requires a JavaScript-enabled browser.
        </noscript>
    </div>
    <div id="text-content">
        <section>  

            <h1>
                <font class="fbox" color="#FF5100">Fruity Box</font>
                <span id="jummboxPlant" style="display: inline; color:#62a13b"></span>
            </h1>
			
			<strong id="introduction">
				<center><t id="randomtext">FruityBox That's because i like all of fruit's</t></font></center>
            </strong>
			
			<p>
                <center><font color="#ed908a">FruityBox is distribution  of <a href="https://slarmoo.github.io/" target="_blank">Slarmoo</a> </font></center>
			</p>

			<p>
				<font color="#edbebb">FruityBox was made to create music with more customisation !</font>
			</p>
			<p>
				<font color="#edbebb">The original program beepbox made by <font color="#adeeeb">John Neski</font> </font> <br>
				<font color="#edbebb">Mod is maded by <font color="#adeeeb">Kashumy Github/Krystian</font> </font>
            </p>
            <p id="introduction">
             FruityBox is a tool for making and sharing your music. Make sure that your volume is turned up, then press the play button!
            </p>
			<p style="text-align: center;"></p>
            <p>
  
            </p>
        </section>

        <div class="column-container">
            <main class="instructions-column">
 
 
            </main>
 
        </div>
        </div>
<script>
let randomarr2=["‚âΩ(‚óï ·¥ó ‚óï)‚âº", "‚âΩ(·¥ó _ ·¥ó)‚âº", "‚âΩ(‚åê _ ‚åê)‚âº", "‚âΩ(·µï ‚Äø ·µï)‚âº", "‚ô•Ô∏è","üíö","üå∫","üå∑","üåπ","üíê","üåø","üåæ","üåµ","üçÄ","‚òòÔ∏è","üå≤","üå≥","ü™®","‚õ∞Ô∏è","‚ú®","üçâ","üçë","üçä","üçí","üçì","ü•≠","üçç","üçå","üåΩ","üçã","ü•ë","ü´ê","üçá","üö¥","üëã","üíÄ","`\\(`^`)/`","‚òï","üé§"]
let randomarr=["Wacky Box!",
"FruityBox That's because of the fruit's inside of it","You can 'Make A Music' ",
"Lol I installed Ransomware :D","WHO READS DESCRIPTION",
"Im a chiptune do you?",
"Added Some Weird Changes But thats no matter.",
"Did you know ol version of FruityBox is less responsible with json songs from slarmoo LOL",
"...",
" Is Your JavaScript Enabled ? ",
"I just putted here random useless long text just to make you read this for no reason . Also did you know you can disable showdescription in preferences",
"Please don't feed the synthesizer",
"404 Melody Not Found","808 Error not found ",
"You can use samples!",
"I accidentally made dubstep...",
"Forgot to save json music üò¨",
"Maded Earrape on accident ..",
"W",
"Please, for the love of God, do not increase the master gain and lower the second ratio.",
"Why are you reading this?",
"Too much bass is never enough",
"Now featuring at least one sound",
"The melody you made is now sent to space. Lol im joking this is not consistent with user privacy ",
"Composed entirely in a caffeine frenzy",
"Making music with the blender is Crazy.",
"We don't steal your data ! Just Like in the other beepbox mods",
 "Dont make repetitive patterns you can make better song by instant changing it."
]
document.getElementById("randomtext").innerText= randomarr[parseInt(Math.random()*randomarr.length)]

document.getElementById("jummboxPlant").innerText= randomarr2[parseInt(Math.random()*randomarr2.length)]
</script>
        
         
  <style>
     .white-key{
      color:#3B3B3B !important;
     }
    .file-item {
      background: #FFFFFF;
      margin: 0.5rem 0;
      padding: 1rem;
      color:#000000;
      border: 1px solid #F6F6F6;
      border-radius: 6px;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }
    .file-item span {
      flex: 1;
    }
    .file-item button {
      margin-left: 1rem;
    }
    .menu {
      margin-top: 1rem;
    }
    #fileList{
        background:#252525;
        min-width:90vw;
        min-height:50px;
        max-height:400px; overflow: hidden scroll;
    }
#themeList{
        background:#252525;
        min-width:90vw;
        min-height:50px;
        max-height:400px; overflow: hidden scroll;
    }
  </style>
  
 <div id="plugins-content">
<move id="main2"></move>
  
<h1>SAMPLER MANAGER</h1>
<details>
  <input type="file" id="fileInput" accept=".mp3,.wav,.ogg,.m4a">
  <div class="menu">
    <label>Sample name:</label>
    <input id="varname" type="text">
    <label>Compression larger number smaller compression:</label>
    <input id="compressionLevel" type="number" min="2" max="1000" value="10000">
 <label>Max Sample Length:</label>
    <input id="audiolength" type="number" min="100" max="2500000" value="250000" placeholder="250000">
 
<label><input type="checkbox" onclick="let truety=this.checked; document.getElementById('notetron').style.display=!truety?'block':'none';document.getElementById('detunator').style.display=truety?'block':'none'; if(isFileIn==1){ document.getElementById('generateButton').disabled = !truety; document.getElementById('generateButton2').disabled = truety;}" id="rootNoteMode"> Mode </label>
<label id="notetron" style="display:block;"  >Root Note:<input id="rootnotekey" type="number" oninput="document.getElementById('rootNote').innerText=_noteNameFromPitchNumber(this.value)" min="0" max="127" value="60" placeholder="MIDI root key"> <text id="rootNote">C4</text></label>
<label id="detunator" style="display:none;" >Detune:<input id="detunesample"   type="number" min="-55" max="55" placeholder="detune" value="-55"></label>

<text id="detectednote"> </text>
<input id="expressions" type="number" min="0.5" max="5" placeholder="expression" value="1.0">
    <button id="generateButton2" disabled>Create with root</button>
    <button id="generateButton" disabled>Create</button>
    <button id="reload" >Reload</button>
  </div>
all your samples will be generated in wave for chipwave at the bottom  
  <div id="fileList"></div>
  <div><button id="generateZip" >Save As Zip</button>
    <button id="importZipReplace" >Import Zip And Remove All</button>
    <button id="importZip" >Import Zip Add</button></div>
<script>
let Config = {};
Config.keys = [
  { name: "C", isWhiteKey: true, basePitch: 0 },
  { name: "C‚ôØ", isWhiteKey: false, basePitch: 1 },
  { name: "D", isWhiteKey: true, basePitch: 2 },
  { name: "D‚ôØ", isWhiteKey: false, basePitch: 3 },
  { name: "E", isWhiteKey: true, basePitch: 4 },
  { name: "F", isWhiteKey: true, basePitch: 5 },
  { name: "F‚ôØ", isWhiteKey: false, basePitch: 6 },
  { name: "G", isWhiteKey: true, basePitch: 7 },
  { name: "G‚ôØ", isWhiteKey: false, basePitch: 8 },
  { name: "A", isWhiteKey: true, basePitch: 9 },
  { name: "A‚ôØ", isWhiteKey: false, basePitch: 10 },
  { name: "B", isWhiteKey: true, basePitch: 11 },
];
Config.pitchesPerOctave = 12;

function _noteNameFromPitchNumber(n) {
  n = Math.floor(n);
  const octave = Math.floor(n / Config.pitchesPerOctave) - 1;
  const index = ((n % Config.pitchesPerOctave) + Config.pitchesPerOctave) % Config.pitchesPerOctave;
  const key = Config.keys[index];
  if (!key) return "?";

  return key.name + octave;
}


function floatToWav(samples, sampleRate = 44100) { 
  const buffer = new ArrayBuffer(44 + samples.length * 2);
  const view = new DataView(buffer);
  function writeString(view, offset, string) {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  }
  writeString(view, 0, 'RIFF');
  view.setUint32(4, 36 + samples.length * 2, true);
  writeString(view, 8, 'WAVE');
  writeString(view, 12, 'fmt ');
  view.setUint32(16, 16, true); 
  view.setUint16(20, 1, true);  
  view.setUint16(22, 1, true); 
  view.setUint32(24, sampleRate, true); 
  view.setUint32(28, sampleRate * 2, true); 
  view.setUint16(32, 2, true);  
  view.setUint16(34, 16, true); 
  writeString(view, 36, 'data');
  view.setUint32(40, samples.length * 2, true);
  for (let i = 0; i < samples.length; i++) {
    let s = Math.max(-1, Math.min(1, samples[i]));
    view.setInt16(44 + i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
  }
  return new Blob([view], { type: 'audio/wav' });
}
async function audioFileToBuffer(file) {
  const arrayBuffer = await file.arrayBuffer();
  const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
  const channelData = audioBuffer.getChannelData(0);
  return Array.from(channelData);
}

function blobToBase6422(blob) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => {
      const base64data = reader.result.split(',')[1];
      resolve(base64data);
    };
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
}
document.getElementById('generateZip').addEventListener('click', async () => {
  const zip = new JSZip();

  for (const id in filesMap) {
    const file = filesMap[id];
 
    const wavBlob = floatToWav(file.buffer, 44100);
 
    zip.file(`${file.name}.wav`, wavBlob);
    const meta = {
      extradetune: file.extradetune,
      expression: file.expression,
      rootNote: file.rootNote
    };
    zip.file(`${file.name}.json`, JSON.stringify(meta));
  }

  const blob = await zip.generateAsync({ type: 'blob' });
  const a = document.createElement('a');
  let src=URL.createObjectURL(blob)
  a.href = src;
  a.download = 'YourSamples.zip';
  a.click();
  if (location.href.startsWith("file:///")) {
	fetch(src)
		.then(response => response.blob())
		.then(blob => blobToBase6422(blob))
		.then(base64data => {
			NativeJava.DownloadFile(base64data, 'YourSamples.zip');
		});
}
});


  

 


document.getElementById('importZip').addEventListener('click', () => {
  const input = document.createElement('input');
  input.type = 'file';
  input.accept = '.zip';
  input.onchange = async (e) => {
    const file = e.target.files[0];
    const zip = await JSZip.loadAsync(file);
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    for (const relativePath in zip.files) {
      if (relativePath.endsWith('.wav')) {
        const wavFile = zip.files[relativePath];
        const arrayBuffer = await wavFile.async('arraybuffer');
        const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
        const channelData = audioBuffer.getChannelData(0);
        const floatBuffer = Array.from(channelData);
        const baseName = relativePath.replace('.wav', '');
        let extradetune = 0;
        let expression = 0;
        let rootNote = 0;
        if (zip.files[baseName + '.json']) {
          const metaStr = await zip.files[baseName + '.json'].async('string');
          const meta = JSON.parse(metaStr);
          extradetune = meta.extradetune || 0;
          expression = meta.expression || 0;
          rootNote = meta.rootNote ;
        }

        const id = Date.now() + Math.random();
        filesMap[id] = {
          name: baseName,
          buffer: floatBuffer,
          extradetune,
          expression,
          rootNote
        };
        saveBuffer(id, baseName, floatBuffer, extradetune, expression);
      }
    }
    renderFileList();
    loadFiles()
  };
  input.click();
});

document.getElementById('importZipReplace').addEventListener('click', () => {
  const input = document.createElement('input');
  input.type = 'file';
  input.accept = '.zip';
  input.onchange = async (e) => {
    const file = e.target.files[0];
    const zip = await JSZip.loadAsync(file);
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    filesMap = [];
    for (const relativePath in zip.files) {
      if (relativePath.endsWith('.wav')) {
        const wavFile = zip.files[relativePath];
        const arrayBuffer = await wavFile.async('arraybuffer');
        const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
        const channelData = audioBuffer.getChannelData(0);
        const floatBuffer = Array.from(channelData);
        const baseName = relativePath.replace('.wav', '');
        let extradetune = 0;
        let expression = 0;
        let rootNote = 0;
if (zip.files[baseName + '.json']) {
 const metaStr = await zip.files[baseName + '.json'].async('string');
 const meta = JSON.parse(metaStr);
 extradetune = meta.extradetune || 0;
 expression = meta.expression || 0;
 rootNote = meta.rootNote;
}
        const id = Date.now() + Math.random();
        filesMap[id] = {
          name: baseName,
          buffer: floatBuffer,
          extradetune,
          expression,
          rootNote
        };
        saveBuffer(id, baseName, floatBuffer, extradetune, expression);
      }
    }
    renderFileList();
    loadFiles()
  };
  input.click();
});

  
 


</script>

    
    
  <script>
  
 var updateSampledWaves = function() {}
  
  let db , db2;
  let CustomThemes={};
let filesMap = [];
let allfilesloaded = 0;
function saveBuffer(id,name,buffer,extradetune1,expression1,rootnote){
 const transaction=db.transaction(["files"],"readwrite");
 const store=transaction.objectStore("files");
 const obj = { id, name, buffer, expression: expression1 };
if(extradetune1 != null) obj.extradetune = extradetune1;
if(rootnote != null) obj.rootNote = rootnote;
store.put(obj);

 return new Promise(res=>transaction.oncomplete=()=>res());
}
function deleteFile(id) {
 const transaction = db.transaction(["files"], "readwrite");
 const store = transaction.objectStore("files");
 store.delete(id);
}
    function renderFileList() {
      const list = document.getElementById('fileList');
      list.innerHTML = '';
      Object.keys(filesMap).forEach(id => {
        const div = document.createElement('div');
        div.className = 'file-item';
        div.id = `file-${id}`;

        const span = document.createElement('span');
        span.textContent = filesMap[id].name;

        const btn = document.createElement('button');
        btn.textContent = 'X';
        btn.onclick = () => {
          delete filesMap[id];
          deleteFile(Number(id));
          document.getElementById(`file-${id}`).remove();
        };

        div.appendChild(span);
        div.appendChild(btn);
        list.appendChild(div);
      });
    }

    let selectedFile = null;
    let audioContext = new (window.AudioContext || window.webkitAudioContext)();
    let isFileIn=0
    document.getElementById('fileInput').addEventListener('change', (event) => {
      selectedFile = event.target.files[0];
      
      document.getElementById('generateButton').disabled = false;
      document.getElementById('generateButton2').disabled = false;
      isFileIn=1
      const truety=document.getElementById('rootNoteMode').checked; document.getElementById('notetron').style.display=!truety?'block':'none';document.getElementById('detunator').style.display=truety?'block':'none'; if(isFileIn==1){ document.getElementById('generateButton').disabled = !truety; document.getElementById('generateButton2').disabled = truety;}
      const nameField = document.getElementById('varname');
      nameField.value = selectedFile.name.replace(/\.(mp3|wav|ogg)$/i, '');
    });
document.getElementById('generateButton2').addEventListener('click', async () => {
  if (!selectedFile) return;
  const fileId = Date.now();
  const arrayBuffer = await selectedFile.arrayBuffer();
  const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
  const samples = Array.from(audioBuffer.getChannelData(0));
  const sampleArray = samples.map(s => parseFloat(s.toFixed(5)));
  const nameInput = document.getElementById('varname').value.trim();
  const fileName = nameInput ? nameInput : selectedFile.name.replace(/\.(mp3|wav|ogg|m4a)$/i, '');
  let detunesample1 = parseInt(document.getElementById("detunesample").value);
  let rootnotesample1 = parseInt(document.getElementById("rootnotekey").value);
  let expression1 = parseInt(document.getElementById("expressions").value);
  if (document.getElementById("rootNoteMode").checked) {
    POPUP(innerWidth/2-150, innerHeight/2-100 + window.scrollY
     ,"Generating Error",
    		"<text style='color:black'>This S Only For Root Note</text>",
    		"#00afdf"
   	); return;
  } else {
    filesMap[fileId] = { name: fileName, buffer: sampleArray, rootNote: rootnotesample1, expression: expression1 };
    saveBuffer(fileId, fileName, sampleArray, null, expression1, rootnotesample1);
  }
  renderFileList();
  document.getElementById('varname').value = '';
  document.getElementById('fileInput').value = '';
  selectedFile = null;
  document.getElementById('generateButton2').disabled = true;
  loadFiles();
  isFileIn=0
});

    document.getElementById('generateButton').addEventListener('click', async () => {
      if (!selectedFile) return;

      const fileId = Date.now();
      const arrayBuffer = await selectedFile.arrayBuffer();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      const samples = Array.from(audioBuffer.getChannelData(0));

      const semitoneShift = -12;
      const pitchRatio = Math.pow(2, semitoneShift / 12);
      const newLength = Math.floor(samples.length * pitchRatio);
      const shiftedSamples = new Array(newLength);
      for (let i = 0; i < newLength; i++) {
        const srcIndex = i / pitchRatio;
        const low = Math.floor(srcIndex);
        const high = Math.min(low + 1, samples.length - 1);
        const frac = srcIndex - low;
        shiftedSamples[i] = samples[low] * (1 - frac) + samples[high] * frac;
      }

      const compressionLevel = parseInt(document.getElementById('compressionLevel').value);
      const compressedSamples = shiftedSamples.filter((_, index) => index % compressionLevel !== 0);
      const maxSamples = parseInt(document.getElementById("audiolength").value)||250000;
      const croppedSamples = compressedSamples.slice(0, maxSamples);

      const nameInput = document.getElementById('varname').value.trim();
      const fileName = nameInput ? nameInput : selectedFile.name.replace(/\.(mp3|wav|ogg|m4a)$/i, '');
const sampleArray = croppedSamples.map(s => parseFloat(s.toFixed(6)));

 let detunesample1=parseInt(document.getElementById("detunesample").value)
 let rootnotesample1=parseInt(document.getElementById("rootnotekey").value)
  let expression1=parseInt(document.getElementById("expressions").value)

 if(document.getElementById("rootNoteMode").checked){
      filesMap[fileId] = { name: fileName, buffer: sampleArray,extradetune:detunesample1, expression: expression1  };
      saveBuffer(fileId, fileName, sampleArray,detunesample1,expression1);
 }else{
      filesMap[fileId] = { name: fileName, buffer: sampleArray,rootNote:rootnotesample1, expression: expression1  };
      saveBuffer(fileId, fileName, sampleArray,null,expression1,rootnotesample1);
 }
      
      renderFileList();
 
document.getElementById('varname').value = '';
document.getElementById('fileInput').value = '';
selectedFile = null; 
document.getElementById('fileInput').value = '';
document.getElementById('generateButton').disabled = true;
loadFiles()
isFileIn=0
    });
document.getElementById('reload').addEventListener('click', async () => {
	loadFiles()
	renderFileList();
	
});
  </script>
        
        after creating a sample please wait to load sample in the chip wave section 
        share zip file with samples and json music .
        please be patient when youre exporting your samples as zip it takes some time 
    </details>
 
        
        
 
        
    <style>
        #editor_C01 { background: #121212; color: #eee; padding: 20px; font-family: Arial, sans-serif; }
        #editor_C01 input, #editor_C01 button, #editor_C01 audio, #editor_C01 canvas {
            background: #000; border: none; outline: none; box-shadow: none; color: #eee; margin: 5px;
        }
    </style>
    <h1>SAMPLER EDITOR</h1>
<details>
            <div id="editor_C01">
        <input type="file" id="fileInput_C01" accept="audio/*">
        <button id="loadBtn_C01" disabled>Load</button>
        <audio id="audio_C01" controls></audio>
        <span id="duration_C01"></span> <br>
     start   <input type="number" id="startTime_C01" min="0" step="0.01"> <br>
      end  <input type="number" id="endTime_C01" min="0" step="0.01"> <br>
     repeat   <input type="number" id="repeats_C01" min="1" step="1" value="2"> <br>
        <label><input type="checkbox" id="cutOption_C01">Cut only</label> <br>
     pitchshift in semitones   <input type="number" id="pitchShift_C01" value="0" step="1">  <br>
        <button id="loopBtn_C01" disabled>Loop</button>
        <button id="playOutputBtn_C01" disabled>Play</button>
        <button id="exportBtn_C01" disabled>Export</button>
        <audio id="outputAudio_C01" controls style="display:none;width:100%"></audio>
        <canvas id="waveform_C01"></canvas>
        <label>Volume: <input type="number" id="volume_C01" min="0" max="2" step="0.1" value="1"></label>

<button id="addAudioBtn_C01" disabled>connect Audio</button>

    </div>
    </details>
    <script>
 
    let originalBuffer, outputUrl, selection={start:0,end:0,dragging:false};
    var audioCtx=new (window.AudioContext||window.webkitAudioContext)();
const addAudioBtn = document.getElementById('addAudioBtn_C01');
let outputBuffer;
addAudioBtn.disabled = false;
addAudioBtn.addEventListener('click', () => {
    const input = document.createElement('input');
    input.type = 'file';
    input.accept = 'audio/*';
    input.onchange = () => {
        const file = input.files[0];
        if (!file) return;

        const reader = new FileReader();
        reader.onload = () => {
            audioCtx.decodeAudioData(reader.result).then(newBuf => {
                const ch = Math.min(originalBuffer.numberOfChannels, newBuf.numberOfChannels);
                const sr = audioCtx.sampleRate;
                const combined = audioCtx.createBuffer(
                    ch,
                    originalBuffer.length + newBuf.length,
                    sr
                );

                for (let c = 0; c < ch; c++) {
                    const combinedData = combined.getChannelData(c);
                    combinedData.set(originalBuffer.getChannelData(c), 0);
                    combinedData.set(newBuf.getChannelData(c), originalBuffer.length);
                }

                originalBuffer = combined;

                 drawWaveform()
            });
        };
        reader.readAsArrayBuffer(file);
    };
    input.click();
});
const canvas = document.getElementById('waveform_C01');
const ctx = canvas.getContext('2d');
function drawWaveform(){
                canvas.width=canvas.clientWidth; canvas.height=canvas.clientHeight;
                const data=originalBuffer.getChannelData(0);
                const step=Math.ceil(data.length/canvas.width);
                const h=canvas.height/2;
                ctx.clearRect(0,0,canvas.width,canvas.height);
                ctx.strokeStyle='#eee'; ctx.beginPath(); ctx.moveTo(0,h);
                for(let i=0;i<canvas.width;i++){
                    let min=1, max=-1;
                    for(let j=0;j<step;j++){ const v=data[i*step+j]; if(v<min) min=v; if(v>max) max=v; }
                    ctx.lineTo(i,(1+min)*h); ctx.lineTo(i,(1+max)*h);
                }
                ctx.stroke();
                if(selection.start!==selection.end){
                    const x1=selection.start/originalBuffer.duration*canvas.width;
                    const x2=selection.end/originalBuffer.duration*canvas.width;
                    ctx.fillStyle='rgba(0,123,255,0.3)';
                    ctx.fillRect(Math.min(x1,x2),0,Math.abs(x2-x1),canvas.height);
                }
            }
        function openAudioLoopEditor_C01(){
            
            const fileInput=document.getElementById('fileInput_C01');
            const loadBtn=document.getElementById('loadBtn_C01');
            const audioEl=document.getElementById('audio_C01');
            const durationEl=document.getElementById('duration_C01');
            const startInput=document.getElementById('startTime_C01');
            const endInput=document.getElementById('endTime_C01');
            const repeatsInput=document.getElementById('repeats_C01');
            const cutCheckbox=document.getElementById('cutOption_C01');
            const pitchInput=document.getElementById('pitchShift_C01');
            const loopBtn=document.getElementById('loopBtn_C01');
            const playBtn=document.getElementById('playOutputBtn_C01');
            const exportBtn=document.getElementById('exportBtn_C01');
            const outputAudio=document.getElementById('outputAudio_C01');
            
            
            fileInput.addEventListener('change',()=>loadBtn.disabled=!fileInput.files.length);
            loadBtn.addEventListener('click',()=>{
                const file=fileInput.files[0]; if(!file) return;
                audioEl.src=URL.createObjectURL(file);
                audioEl.onloadedmetadata=()=>{
                    durationEl.textContent=`Duration: ${audioEl.duration.toFixed(2)}s`;
                    startInput.max=endInput.max=audioEl.duration;
                    endInput.value=audioEl.duration.toFixed(2);
                    const reader=new FileReader();
                    reader.onload=()=>audioCtx.decodeAudioData(reader.result).then(buf=>{ originalBuffer=buf; drawWaveform(); loopBtn.disabled=false });
                    reader.readAsArrayBuffer(file);
                };
            });
            
            canvas.addEventListener('mousedown',e=>{ selection.dragging=true; const x=(e.clientX-canvas.getBoundingClientRect().left)/canvas.width*originalBuffer.duration; selection.start=selection.end=x; drawWaveform(); });
            canvas.addEventListener('mousemove',e=>{ if(!selection.dragging) return; const x=(e.clientX-canvas.getBoundingClientRect().left)/canvas.width*originalBuffer.duration; selection.end=x; drawWaveform(); });
            window.addEventListener('mouseup',()=>{ if(selection.dragging){ selection.dragging=false; drawWaveform(); }});
            [startInput,endInput].forEach(inp=>inp.addEventListener('change',()=>{
                if(!originalBuffer) return;
                const s=parseFloat(startInput.value), e=parseFloat(endInput.value);
                selection.start=Math.max(0,Math.min(s,originalBuffer.duration));
                selection.end=Math.max(0,Math.min(e,originalBuffer.duration));
                drawWaveform();
            }));
            loopBtn.addEventListener('click', () => {
    if (!originalBuffer) return;
    audioCtx.resume().then(() => {
        const s = Math.min(selection.start, selection.end);
        const e = Math.max(selection.start, selection.end);
        const r = parseInt(repeatsInput.value, 10);
        const sr = originalBuffer.sampleRate;
        const ss = Math.floor(s * sr), es = Math.floor(e * sr);
        const len = es - ss;
        const ch = originalBuffer.numberOfChannels;
        if (cutCheckbox.checked) {
            outputBuffer = audioCtx.createBuffer(ch, len * r, sr);
            for (let c = 0; c < ch; c++) {
                const seg = originalBuffer.getChannelData(c).slice(ss, es);
                for (let i = 0; i < r; i++) outputBuffer.getChannelData(c).set(seg, i * len);
            }
        } else {
            const before = ss, after = originalBuffer.length - es;
            outputBuffer = audioCtx.createBuffer(ch, before + len * r + after, sr);
            for (let c = 0; c < ch; c++) {
                const od = originalBuffer.getChannelData(c);
                const odr = outputBuffer.getChannelData(c);
                odr.set(od.slice(0, ss), 0);
                const seg = od.slice(ss, es);
                for (let i = 0; i < r; i++) odr.set(seg, before + i * len);
                odr.set(od.slice(es), before + len * r);
            }
        }
        const semitones = parseInt(pitchInput.value, 10);
        const ratio = Math.pow(2, semitones / 12);
        const newLen = Math.floor(outputBuffer.length / ratio);
        const volumeGain = parseFloat(document.getElementById('volume_C01').value) || 1;
        const pitched = audioCtx.createBuffer(outputBuffer.numberOfChannels, newLen, outputBuffer.sampleRate);
        for (let c = 0; c < outputBuffer.numberOfChannels; c++) {
            const inp = outputBuffer.getChannelData(c);
            const out = pitched.getChannelData(c);
            for (let i = 0; i < newLen; i++) {
                const idx = i * ratio;
                const lo = Math.floor(idx);
                const hi = Math.min(lo + 1, inp.length - 1);
                const f = idx - lo;
                out[i] = (inp[lo] * (1 - f) + inp[hi] * f) * volumeGain;
            }
        }
        if (outputUrl) URL.revokeObjectURL(outputUrl);
        outputUrl = URL.createObjectURL(encodeWAV(pitched));
        outputAudio.src = outputUrl;
        outputAudio.style.display = 'block';
        playBtn.disabled = false;
        exportBtn.disabled = false;
        outputAudio.play().catch(() => {});
    });
});
function blobToBase642(blob) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => {
      const base64data = reader.result.split(',')[1];
      resolve(base64data);
    };
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
}
playBtn.addEventListener('click',()=>{ if(outputAudio.src) outputAudio.play().catch(()=>{}); });
exportBtn.addEventListener('click', () => {
	const outputAudio = document.getElementById('outputAudio_C01');
	const src = outputAudio.src;
	
	if (!src) return;
	
	const a = document.createElement('a');
	a.href = src;
	a.download = 'output_audio.wav';
	a.click();
	if (location.href.startsWith("file:///")) {
		fetch(src)
			.then(response => response.blob())
			.then(blob => blobToBase642(blob))
			.then(base64data => {
				NativeJava.DownloadFile(base64data, 'output_audio.wav');
			});
	}
});

            function encodeWAV(buf){
                const ch=buf.numberOfChannels, sr=buf.sampleRate, bps=16, samps=buf.length;
                const ba=ch*bps/8, len=44+samps*ch*2; const ab=new ArrayBuffer(len); const dv=new DataView(ab);
                function w(s,o){ for(let i=0;i<s.length;i++) dv.setUint8(o+i,s.charCodeAt(i)); }
                w('RIFF',0); dv.setUint32(4,36+samps*ch*2,true); w('WAVE',8); w('fmt ',12);
                dv.setUint32(16,16,true); dv.setUint16(20,1,true); dv.setUint16(22,ch,true);
                dv.setUint32(24,sr,true); dv.setUint32(28,sr*ba,true); dv.setUint16(32,ba,true); dv.setUint16(34,bps,true);
                w('data',36); dv.setUint32(40,samps*ch*bps/8,true);
                let off=44;
                for(let i=0;i<samps;i++){
                    for(let c=0;c<ch;c++){
                        let v=buf.getChannelData(c)[i];
                        v=Math.max(-1,Math.min(1,v));
                        dv.setInt16(off,v<0?v*0x8000:v*0x7FFF,true);
                        off+=2;
                    }
                }
                return new Blob([ab],{type:'audio/wav'});
            }
        }
        openAudioLoopEditor_C01();
    </script>
        


    <!--
    Instead of loading js beepbox editor interface directly, test for browser support.
    <script type="text/javascript" src="beepbox_editor.min.js"></script>
    -->
    <script type="text/javascript">

 
        if (/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini|android|ipad|playbook|silk/i.test(navigator.userAgent)) {
             
        }

        function browserHasRequiredFeatures() {
            "use strict";
            if (window.AudioContext == undefined && window.webkitAudioContext == undefined) {
                return false;
            }

            try {
                eval("class T {}");
                eval("const a = () => 0");
                eval("for (const a of []);");
            } catch (error) {
                return false;
            }

            return true;
        }

        if (browserHasRequiredFeatures()) {
            var fileref = document.createElement("script");
            fileref.setAttribute("type", "text/javascript");
            fileref.setAttribute("src", "beepbox_editor.js");
            document.head.appendChild(fileref);
        } else {
            document.getElementById("beepboxEditorContainer").innerHTML = "Sorry, JummBox doesn't support your browser. Try a recent version of Chrome, Firefox, Edge, Safari, or Opera.";
        }
		if (/^#[1-6]/.test(location.hash)) {
			document.getElementById("linkTo2_3").href += location.hash;
		}
		if (/^#[1-8]/.test(location.hash)) {
			document.getElementById("linkTo3_0").href += location.hash;
		}
    </script>
</body>
</html>
<script>
 
function applyZoom() {
      const isMobile = /Mobi|Android|iPhone/i.test(navigator.userAgent);
      const isLandscape = window.matchMedia("(orientation: landscape)").matches;
      if (isMobile && isLandscape) {
        document.body.style.zoom = "0.5";
      } else {
        document.body.style.zoom = "1";
      }
    }

 
  
</script>
  <h1>Fade-out Plugin </h1>
  <details>

  <p id="audioLength" style="margin-top:1rem;">Audio Length: <span id="lengthVal">0</span> seconds</p>

  <input type="file" id="fileInput88" accept=".wav" />
  
  <div style="margin-top: 1rem; padding: 1rem; background: #222; border-radius: 8px;">
    <label>
      Fade End (seconds):
      <input type="number" id="fadeEnd" value="10" step="0.1" min="0" />
    </label>
    <br>
    <label>
      Fade Duration (seconds):
      <input type="number" id="fadeTime" value="2" step="0.1" min="0" />
    </label>
    <br>
    <label>
      End Of Silence (seconds):
      <input type="number" id="endSilence" value="0" step="0.1" min="0" />
    </label>
  </div>

  <button id="downloadButton34">Download</button>
</details>
  <script>
    let audioCtx22 = new (window.AudioContext || window.webkitAudioContext)();
    let audioBuffer22 = null;

    document.getElementById('fileInput88').addEventListener('change', async (e) => {
  const file = e.target.files[0];
  if (!file) return alert("Please select a file.");
  const arrayBuffer = await file.arrayBuffer();
  audioBuffer22 = await audioCtx22.decodeAudioData(arrayBuffer);
  document.getElementById('lengthVal').textContent = audioBuffer22.duration.toFixed(2);
  alert("File loaded successfully.");
});


    document.getElementById('downloadButton34').addEventListener('click', async () => {
  if (!audioBuffer22) return alert("Please load an audio file first.");

  const duration = audioBuffer22.duration;
  const sampleRate = audioBuffer22.sampleRate;

  const fadeEndSeconds = parseFloat(document.getElementById('fadeEnd').value);
  const fadeDurationSeconds = parseFloat(document.getElementById('fadeTime').value);
  const endSilenceSeconds = parseFloat(document.getElementById('endSilence').value);

  let fadeEnd = duration - fadeEndSeconds;
  if (fadeEnd < 0) fadeEnd = 0;

  let fadeStart = fadeEnd - fadeDurationSeconds;
  if (fadeStart < 0) fadeStart = 0;

  const extraSamples = Math.floor(endSilenceSeconds * sampleRate);
  const totalLength = audioBuffer22.length + extraSamples;

  const ctx = new OfflineAudioContext(
    audioBuffer22.numberOfChannels,
    totalLength,
    sampleRate
  );

  const source = ctx.createBufferSource();
  source.buffer = audioBuffer22;

  const gain = ctx.createGain();
  gain.gain.setValueAtTime(1, 0);

  if (fadeEndSeconds > 0 && fadeDurationSeconds > 0) {
    gain.gain.setValueAtTime(1, fadeStart);
    gain.gain.linearRampToValueAtTime(0, fadeEnd);
  }

  source.connect(gain).connect(ctx.destination);
  source.start();

  const rendered = await ctx.startRendering();
  const wav = encodeWAV(rendered);
  const blob = new Blob([wav], { type: 'audio/wav' });

  if (location.href.startsWith("file:///") ) {
    blob.arrayBuffer().then(buffer => {
      const base64data = arrayBufferToBase64(buffer);
      NativeJava.DownloadFile(base64data, 'output_audio.wav');
    });
  } else {
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = 'fadeout.wav';
    a.click();
    URL.revokeObjectURL(url);
  }
});


    function encodeWAV(buffer) {
      const channels = buffer.numberOfChannels;
      const sampleRate = buffer.sampleRate;
      const length = buffer.length;
      const bitsPerSample = 16;
      const bytesPerSample = bitsPerSample / 8;
      const blockAlign = channels * bytesPerSample;
      const byteRate = sampleRate * blockAlign;
      const dataSize = length * blockAlign;

      const bufferView = new DataView(new ArrayBuffer(44 + dataSize));
      let offset = 0;

      const writeString = (str) => {
        for (let i = 0; i < str.length; i++) {
          bufferView.setUint8(offset++, str.charCodeAt(i));
        }
      };

      writeString('RIFF');
      bufferView.setUint32(offset, 36 + dataSize, true); offset += 4;
      writeString('WAVE');
      writeString('fmt ');
      bufferView.setUint32(offset, 16, true); offset += 4;
      bufferView.setUint16(offset, 1, true); offset += 2;
      bufferView.setUint16(offset, channels, true); offset += 2;
      bufferView.setUint32(offset, sampleRate, true); offset += 4;
      bufferView.setUint32(offset, byteRate, true); offset += 4;
      bufferView.setUint16(offset, blockAlign, true); offset += 2;
      bufferView.setUint16(offset, bitsPerSample, true); offset += 2;
      writeString('data');
      bufferView.setUint32(offset, dataSize, true); offset += 4;

      for (let i = 0; i < length; i++) {
        for (let ch = 0; ch < channels; ch++) {
          let sample = buffer.getChannelData(ch)[i];
          sample = Math.max(-1, Math.min(1, sample));
          bufferView.setInt16(offset, sample * 32767, true);
          offset += 2;
        }
      }

      return bufferView.buffer;
    }

    function arrayBufferToBase64(buffer) {
      let binary = '';
      const bytes = new Uint8Array(buffer);
      for (let i = 0; i < bytes.length; i++) {
        binary += String.fromCharCode(bytes[i]);
      }
      return btoa(binary);
    }
  </script>






  <h1>Reverse Plugin</h1>
  <details>
<div style="font-family: sans-serif; background: #111; color: #fff; padding: 2rem;">

  <p id="audioLength2" style="margin-top:1rem;">Audio Length: <span id="lengthVal2">0</span> seconds</p>

  <input type="file" id="fileInput882" accept=".wav" />
  <button id="downloadButton342">Download</button>

  <script>
    let audioCtx222 = new (window.AudioContext || window.webkitAudioContext)();
    let audioBuffer222 = null;

    document.getElementById('fileInput882').addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return alert("Please select a file.");
      const arrayBuffer = await file.arrayBuffer();
      audioBuffer222 = await audioCtx222.decodeAudioData(arrayBuffer);
      document.getElementById('lengthVal2').textContent = audioBuffer222.duration.toFixed(2);
      alert("File loaded successfully.");
    });

    document.getElementById('downloadButton342').addEventListener('click', async () => {
      if (!audioBuffer222) return alert("Please load an audio file first.");
      const reversedBuffer = audioCtx222.createBuffer(
        audioBuffer222.numberOfChannels,
        audioBuffer222.length,
        audioBuffer222.sampleRate
      );
      for (let ch = 0; ch < audioBuffer222.numberOfChannels; ch++) {
        const input = audioBuffer222.getChannelData(ch);
        const output = reversedBuffer.getChannelData(ch);
        for (let i = 0, j = input.length - 1; i < input.length; i++, j--) {
          output[i] = input[j];
        }
      }
      const ctx = new OfflineAudioContext(
        reversedBuffer.numberOfChannels,
        reversedBuffer.length,
        reversedBuffer.sampleRate
      );
      const source = ctx.createBufferSource();
      source.buffer = reversedBuffer;
      source.connect(ctx.destination);
      source.start();
      const rendered = await ctx.startRendering();
      const wav = encodeWAV(rendered);
      const blob = new Blob([wav], { type: 'audio/wav' });
      if (location.href.startsWith("file:///")) {
        blob.arrayBuffer().then(buffer => {
          const base64data = arrayBufferToBase64(buffer);
          NativeJava.DownloadFile(base64data, 'reversed_audio.wav');
        });
      } else {
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = 'reversed_audio.wav';
        a.click();
        URL.revokeObjectURL(url);
      }
    });

    function encodeWAV(buffer) {
      const channels = buffer.numberOfChannels;
      const sampleRate = buffer.sampleRate;
      const length = buffer.length;
      const bitsPerSample = 16;
      const bytesPerSample = bitsPerSample / 8;
      const blockAlign = channels * bytesPerSample;
      const byteRate = sampleRate * blockAlign;
      const dataSize = length * blockAlign;

      const bufferView = new DataView(new ArrayBuffer(44 + dataSize));
      let offset = 0;

      const writeString = (str) => {
        for (let i = 0; i < str.length; i++) {
          bufferView.setUint8(offset++, str.charCodeAt(i));
        }
      };

      writeString('RIFF');
      bufferView.setUint32(offset, 36 + dataSize, true); offset += 4;
      writeString('WAVE');
      writeString('fmt ');
      bufferView.setUint32(offset, 16, true); offset += 4;
      bufferView.setUint16(offset, 1, true); offset += 2;
      bufferView.setUint16(offset, channels, true); offset += 2;
      bufferView.setUint32(offset, sampleRate, true); offset += 4;
      bufferView.setUint32(offset, byteRate, true); offset += 4;
      bufferView.setUint16(offset, blockAlign, true); offset += 2;
      bufferView.setUint16(offset, bitsPerSample, true); offset += 2;
      writeString('data');
      bufferView.setUint32(offset, dataSize, true); offset += 4;

      for (let i = 0; i < length; i++) {
        for (let ch = 0; ch < channels; ch++) {
          let sample = buffer.getChannelData(ch)[i];
          sample = Math.max(-1, Math.min(1, sample));
          bufferView.setInt16(offset, sample * 32767, true);
          offset += 2;
        }
      }

      return bufferView.buffer;
    }

    function arrayBufferToBase64(buffer) {
      let binary = '';
      const bytes = new Uint8Array(buffer);
      for (let i = 0; i < bytes.length; i++) {
        binary += String.fromCharCode(bytes[i]);
      }
      return btoa(binary);
    }
  </script>
</div>

  </details>


  <h2>Advanced Audio Editor </h2>
  <details>

<div style="font-family: sans-serif; background: #111; color: #fff; padding: 2rem;">

 
  <style>
    #UUID18289WF { border: none; width: 100%; height: 150px; touch-action: none; background: #000000;}
  </style>
 

  <input type="file" id="UUID18289FILEINPUT" accept=".wav" /><br /><br />
  <canvas id="UUID18289WF" width="800" height="150"></canvas> <br />
  <label>selected Volume:
    <input type="range" id="UUID18289VOLUMESLIDER" min="0" max="2" step="0.01" value="1" />
    <span id="volumeValue">1.00</span>
  </label> <br><button id="UUID18289UNDO">Undo</button> <br>File Audio <input type="file" id="UUID18289REPLACE" accept=".wav" /> <br>
<button id="UUID18289REMOVE">Remove</button>
<button id="UUID18289REPLBTN" style="display:none;">Replace</button>
<button id="UUID18289AUDBTN">AddAudio</button>
<button id="UUID18289SILENCE" style="display:none;" >AddSilence</button>
<button id="UUID18289PLAYSELECTED">Play Selected</button>
<br><br>
<label>Pitch Shift (semitones): <input type="number" id="UUID18289PITCHSHFT" value="0" step="1" /></label><br>
<label>Detune (Hz): <input type="number" id="UUID18289DETUNE" value="0" step="1" /></label><br>
<button id="UUID18289APPLYPITCHETC">Apply Detune and Pitchshift on Selected Fragment</button>

<br><br>
<button onclick="UUID18289PLAYBUFFER(UUID18289CUBUFF);" >Play</button><br>
  <audio id="UUID18289AUDIOPLAYER" controls></audio>
<button onclick="EXPORTBUFFERUID6()" >Download</button>
</details>
<script>
const UUID18289CANVAS = document.getElementById('UUID18289WF');
const UUID18289CTX = UUID18289CANVAS.getContext('2d');
const UUID18289FILEINPUT = document.getElementById('UUID18289FILEINPUT');
const UUID18289VOLUMESLIDER = document.getElementById('UUID18289VOLUMESLIDER');
const UUID18289SILENCE=document.getElementById("UUID18289SILENCE")
const volumeValue = document.getElementById('volumeValue');
const UUID18289AUDIOPLAYER = document.getElementById('UUID18289AUDIOPLAYER');
function blobToBase642(blob) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => {
      const base64data = reader.result.split(',')[1];
      resolve(base64data);
    };
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
}
function EXPORTBUFFERUID6(){
	const outputAudio = document.getElementById('UUID18289AUDIOPLAYER');
	const src = outputAudio.src;
	if (!src) return;
	const a = document.createElement('a');
	a.href = src;
	a.download = 'outputEditedAdvancedAudio.wav';
	a.click();
	if (location.href.startsWith("file:///") ) {
		fetch(src)
			.then(response => response.blob())
			.then(blob => blobToBase642(blob))
			.then(base64data => {
				NativeJava.DownloadFile(base64data, 'outputEditedAdvancedAudio.wav');
			});
	}
}
let audioUUID18289CTX = new (window.AudioContext || window.webkitAudioContext)();
let UUID18289OB = null;
let UUID18289SELECTION = null;
let UUID18289CLICKSTATE = 0;
let UUID18289_SCALEX = 1;
let UUID18289_SCROLLX = 0;
let UUID18289CUBUFF = null;
const UUID18289UNDOSTACK = [];

function saveUndo() {
	if (!UUID18289CUBUFF) return;
	if (UUID18289UNDOSTACK.length >= 20) UUID18289UNDOSTACK.shift();
	const copy = audioUUID18289CTX.createBuffer(UUID18289CUBUFF.numberOfChannels, UUID18289CUBUFF.length, UUID18289CUBUFF.sampleRate);
	for (let ch = 0; ch < copy.numberOfChannels; ch++) {
		copy.copyToChannel(UUID18289CUBUFF.getChannelData(ch), ch);
	}
	UUID18289UNDOSTACK.push(copy);
}
document.getElementById('UUID18289APPLYPITCHETC').addEventListener('click', async () => {
  if (!UUID18289CUBUFF || !UUID18289SELECTION || UUID18289SELECTION.x2 === null) return;

  const semitones = parseFloat(document.getElementById('UUID18289PITCHSHFT').value);
  const detuneHz = parseFloat(document.getElementById('UUID18289DETUNE').value);

  const start = Math.floor(UUID18289SELECTION.x1);
  const end = Math.floor(UUID18289SELECTION.x2);
  const length = end - start;

  const fragment = audioUUID18289CTX.createBuffer(UUID18289CUBUFF.numberOfChannels, length, UUID18289CUBUFF.sampleRate);

  for (let ch = 0; ch < UUID18289CUBUFF.numberOfChannels; ch++) {
    fragment.copyToChannel(UUID18289CUBUFF.getChannelData(ch).slice(start, end), ch);
  }

  const rate = Math.pow(2, semitones / 12);
  const detuneFactor = (detuneHz + UUID18289CUBUFF.sampleRate) / UUID18289CUBUFF.sampleRate;

  const playbackRate = rate * detuneFactor;

  const rendered = await applyPitchDetune(fragment, playbackRate);
  saveUndo();
  const newRenderedLength = rendered.length;
UUID18289SELECTION.x2 = UUID18289SELECTION.x1 + newRenderedLength;
  const newLength = UUID18289CUBUFF.length - length + rendered.length;
  const newBuf = audioUUID18289CTX.createBuffer(UUID18289CUBUFF.numberOfChannels, newLength, UUID18289CUBUFF.sampleRate);

  for (let ch = 0; ch < newBuf.numberOfChannels; ch++) {
    const old = UUID18289CUBUFF.getChannelData(ch);
    const out = newBuf.getChannelData(ch);
    out.set(old.slice(0, start));
    out.set(rendered.getChannelData(ch), start);
    out.set(old.slice(end), start + rendered.length);
  }
  UUID18289CUBUFF = newBuf;
  drawUUID18289WF(UUID18289CUBUFF);
});

async function applyPitchDetune(buffer, playbackRate) {
  const offlineUUID18289CTX = new OfflineAudioContext(
    buffer.numberOfChannels,
    Math.ceil(buffer.length / playbackRate), 
    buffer.sampleRate
  );

  const src = offlineUUID18289CTX.createBufferSource();
  src.buffer = buffer;
  src.playbackRate.value = playbackRate;
  src.connect(offlineUUID18289CTX.destination);
  src.start(0);

  return await offlineUUID18289CTX.startRendering();
}
document.getElementById("UUID18289SILENCE").addEventListener("click", function () {
  if (!UUID18289CUBUFF || !UUID18289SELECTION || UUID18289SELECTION.x2 === null) return;

  saveUndo(); 

  const x1 = Math.floor(UUID18289SELECTION.x1);
  const x2 = Math.floor(UUID18289SELECTION.x2);
  const silenceLength = Math.abs(x2 - x1);
  const newLength = UUID18289CUBUFF.length + silenceLength;

  const newBuf = audioUUID18289CTX.createBuffer(
    UUID18289CUBUFF.numberOfChannels,
    newLength,
    UUID18289CUBUFF.sampleRate
  );
  x1fin= x1+silenceLength 
  if(x2<x1){
    x1fin=x1
  }
  
  for (let ch = 0; ch < UUID18289CUBUFF.numberOfChannels; ch++) {
    const old = UUID18289CUBUFF.getChannelData(ch);
    const out = newBuf.getChannelData(ch);
    out.set(old.slice(0, x1fin), 0);
    for (let i = 0; i < silenceLength; i++) {
      out[x1fin + i] = 0;
    }
    out.set(old.slice(x1fin), x1fin + silenceLength);
  }

  UUID18289CUBUFF = newBuf;
  UUID18289SELECTION = null;
  drawUUID18289WF(UUID18289CUBUFF);
});


document.getElementById('UUID18289PLAYSELECTED').addEventListener('click', () => {
  if (!UUID18289CUBUFF || !UUID18289SELECTION || UUID18289SELECTION.x2 === null) return;

  const startSample = Math.floor(UUID18289SELECTION.x1);
  const endSample = Math.floor(UUID18289SELECTION.x2);
  const length = endSample - startSample;

  const selectedBuffer = audioUUID18289CTX.createBuffer(
    UUID18289CUBUFF.numberOfChannels,
    length,
    UUID18289CUBUFF.sampleRate
  );

  for (let ch = 0; ch < UUID18289CUBUFF.numberOfChannels; ch++) {
    const src = UUID18289CUBUFF.getChannelData(ch);
    const dst = selectedBuffer.getChannelData(ch);
    dst.set(src.slice(startSample, endSample));
  }

  UUID18289PLAYBUFFER(selectedBuffer);
});

document.getElementById('UUID18289UNDO').addEventListener('click', () => {
  if (UUID18289UNDOSTACK.length === 0) return;
  UUID18289CUBUFF = UUID18289UNDOSTACK.pop();
  drawUUID18289WF(UUID18289CUBUFF);
});

UUID18289VOLUMESLIDER.addEventListener('change', () => {
  if (!UUID18289OB || !UUID18289SELECTION || UUID18289SELECTION.x2 === null) return;
  applyVolume();
  drawUUID18289WF(UUID18289CUBUFF);
});

UUID18289VOLUMESLIDER.addEventListener('input', () => {
  volumeValue.textContent = parseFloat(UUID18289VOLUMESLIDER.value).toFixed(2);
});

UUID18289FILEINPUT.addEventListener('change', async (e) => {
  const file = e.target.files[0];
  if (!file) return;
  const arrayBuffer = await file.arrayBuffer();
  UUID18289OB = await audioUUID18289CTX.decodeAudioData(arrayBuffer);
  UUID18289CUBUFF = UUID18289OB;
  UUID18289_SCALEX = 1;
  UUID18289_SCROLLX = 0;
  UUID18289SELECTION = null;
  UUID18289CLICKSTATE = 0;
  drawUUID18289WF(UUID18289CUBUFF);
});
document.getElementById('UUID18289REMOVE').addEventListener('click', () => {
  if (!UUID18289OB || !UUID18289SELECTION || UUID18289SELECTION.x2 === null) return;
  saveUndo();
  const len = UUID18289CUBUFF.length - (UUID18289SELECTION.x2 - UUID18289SELECTION.x1);
  const newBuf = audioUUID18289CTX.createBuffer(UUID18289CUBUFF.numberOfChannels, len, UUID18289CUBUFF.sampleRate);

  for (let ch = 0; ch < newBuf.numberOfChannels; ch++) {
    const old = UUID18289CUBUFF.getChannelData(ch);
    const out = newBuf.getChannelData(ch);
    out.set(old.slice(0, UUID18289SELECTION.x1));
    out.set(old.slice(UUID18289SELECTION.x2), UUID18289SELECTION.x1);
  }

  UUID18289CUBUFF = newBuf;
  UUID18289SELECTION = null;
  drawUUID18289WF(UUID18289CUBUFF);
});

document.getElementById('UUID18289REPLACE').addEventListener('change', async (e) => {
  const file = e.target.files[0];
  if (!file || !UUID18289SELECTION || UUID18289SELECTION.x2 === null) return;
  const arrBuf = await file.arrayBuffer();
  const newAudio = await audioUUID18289CTX.decodeAudioData(arrBuf);

  saveUndo();
  const newLen = UUID18289CUBUFF.length - (UUID18289SELECTION.x2 - UUID18289SELECTION.x1) + newAudio.length;
  const newBuf = audioUUID18289CTX.createBuffer(UUID18289CUBUFF.numberOfChannels, newLen, UUID18289CUBUFF.sampleRate);

  for (let ch = 0; ch < newBuf.numberOfChannels; ch++) {
    const old = UUID18289CUBUFF.getChannelData(ch);
    const out = newBuf.getChannelData(ch);
    out.set(old.slice(0, UUID18289SELECTION.x1));
    out.set(newAudio.getChannelData(Math.min(ch, newAudio.numberOfChannels - 1)), UUID18289SELECTION.x1);
    out.set(old.slice(UUID18289SELECTION.x2), UUID18289SELECTION.x1 + newAudio.length);
  }

  UUID18289CUBUFF = newBuf;
  UUID18289SELECTION = null;
  drawUUID18289WF(UUID18289CUBUFF);
  UUID18289PLAYBUFFER(UUID18289CUBUFF);
});

document.getElementById('UUID18289AUDBTN').addEventListener('click', async () => {
  const input = document.createElement('input');
  input.type = 'file';
  input.accept = '.wav';

  input.onchange = async (e) => {
    const file = e.target.files[0];
    if (!file) return;

    const arrBuf = await file.arrayBuffer();
    const newAudio = await audioUUID18289CTX.decodeAudioData(arrBuf);

    if (typeof UUID18289SELECTION.x1 !== 'number' || isNaN(UUID18289SELECTION.x1)) {
      alert("Select place to add ...");
      return;
    }

    if (!UUID18289CUBUFF) {
      UUID18289CUBUFF = newAudio;
      drawUUID18289WF(UUID18289CUBUFF);
      return;
    }

    const sampleRate = UUID18289CUBUFF.sampleRate;
    const insertSample = Math.floor(UUID18289SELECTION.x1);
    const len = UUID18289CUBUFF.length + newAudio.length;
    const newBuf = audioUUID18289CTX.createBuffer(
      Math.max(UUID18289CUBUFF.numberOfChannels, newAudio.numberOfChannels),
      len,
      sampleRate
    );

    saveUndo();

    for (let ch = 0; ch < newBuf.numberOfChannels; ch++) {
      const out = newBuf.getChannelData(ch);
      const old = UUID18289CUBUFF.getChannelData(Math.min(ch, UUID18289CUBUFF.numberOfChannels - 1));
      const add = newAudio.getChannelData(Math.min(ch, newAudio.numberOfChannels - 1));
      out.set(old.slice(0, insertSample), 0);
      out.set(add, insertSample);
      out.set(old.slice(insertSample), insertSample + add.length);
    }

    UUID18289CUBUFF = newBuf;
    drawUUID18289WF(UUID18289CUBUFF);
  };

  input.click();
});


function clamp(val, min, max) {
  return Math.min(max, Math.max(min, val));
}

function offsetXToSample(offsetX) {
  const rect = UUID18289CANVAS.getBoundingClientRect();
  const UUID18289CANVASX = offsetX - rect.left;
  const visibleSamples = UUID18289CUBUFF.length / UUID18289_SCALEX;
const samplesPerPixel = visibleSamples / UUID18289CANVAS.width*2.5 ;
return ((UUID18289_SCROLLX * visibleSamples + UUID18289CANVASX * samplesPerPixel)
);
}

UUID18289CANVAS.addEventListener('click', (e) => {
  if (!UUID18289OB) return;
  const samplePos = offsetXToSample(e.clientX);

  if (UUID18289SELECTION && UUID18289SELECTION.x1 !== null && UUID18289SELECTION.x2 !== null && samplePos >= UUID18289SELECTION.x1 && samplePos <= UUID18289SELECTION.x2) {
    UUID18289SELECTION = { x1: samplePos, x2: null };
    UUID18289CLICKSTATE = 1;
    drawUUID18289WF(UUID18289CUBUFF);
    return;
  }

  if (UUID18289CLICKSTATE === 0 || !UUID18289SELECTION) {
    UUID18289SELECTION = { x1: clamp(samplePos, 0, UUID18289CUBUFF.length), x2: null };
    UUID18289CLICKSTATE = 1;
  } else {
    UUID18289SELECTION.x2 = clamp(samplePos, 0, UUID18289CUBUFF.length);
    if (UUID18289SELECTION.x2 < UUID18289SELECTION.x1) [UUID18289SELECTION.x1, UUID18289SELECTION.x2] = [UUID18289SELECTION.x2, UUID18289SELECTION.x1];
    UUID18289CLICKSTATE = 0;
  }
  drawUUID18289WF(UUID18289CUBUFF);
});

UUID18289CANVAS.addEventListener('wheel', (e) => {
  if (!UUID18289OB) return;
  e.preventDefault();
  UUID18289_SCROLLX += e.deltaY / (UUID18289_SCALEX * 10);
  const maxScroll = UUID18289OB.length / UUID18289CANVAS.width / UUID18289_SCALEX - UUID18289CANVAS.width / UUID18289_SCALEX;
  UUID18289_SCROLLX = clamp(UUID18289_SCROLLX, 0, Math.max(maxScroll, 0));
  drawUUID18289WF(UUID18289CUBUFF);
}, { passive: false });

let lastTouchX = null;
let lastTouchDist = null;

UUID18289CANVAS.addEventListener('touchstart', (e) => {
  if (e.touches.length === 1) {
    lastTouchX = e.touches[0].clientX;
  } else if (e.touches.length === 2) {
    lastTouchDist = UUID18289GETTOUCHDIST(e);
  }
});
is2Press=0;
UUID18289CANVAS.addEventListener('touchmove', (e) => {
  if (!UUID18289OB ) return;
  e.preventDefault();
  if (e.touches.length === 1 && !is2Press) {
  const touchX = e.touches[0].clientX;
  const deltaPx = lastTouchX - touchX;
  const visibleSamples = UUID18289OB.length / UUID18289_SCALEX;
  const deltaScroll = deltaPx / UUID18289CANVAS.width * clamp(UUID18289_SCALEX,0,20);

  UUID18289_SCROLLX += deltaScroll;
  const maxScroll = (UUID18289OB.length - UUID18289OB.length / UUID18289_SCALEX) / UUID18289OB.length;
UUID18289_SCROLLX = clamp(UUID18289_SCROLLX, 0, maxScroll*UUID18289_SCALEX);

  drawUUID18289WF(UUID18289CUBUFF);
  lastTouchX = touchX;
}
 else if (e.touches.length === 2) {
  const dist = UUID18289GETTOUCHDIST(e);
  const zoomFactor = dist / lastTouchDist;

  const midX = UUID18289GETMIDTOUCH(e);
  const rect = UUID18289CANVAS.getBoundingClientRect();
  const midUUID18289CANVASX = midX - rect.left;

  const visibleSamples = UUID18289OB.length / UUID18289_SCALEX;
  const samplesPerPixel = visibleSamples / UUID18289CANVAS.width;
  const midSample = UUID18289_SCROLLX * UUID18289OB.length + samplesPerPixel * midUUID18289CANVASX;

  UUID18289_SCALEX = clamp(UUID18289_SCALEX * zoomFactor, 1, 60000);
  is2Press=1
  const newVisibleSamples = UUID18289OB.length / UUID18289_SCALEX;
  const maxScroll = (UUID18289OB.length - UUID18289OB.length / UUID18289_SCALEX) / UUID18289OB.length;
  UUID18289_SCROLLX = clamp( UUID18289_SCROLLX , 0, maxScroll*UUID18289_SCALEX);

  drawUUID18289WF(UUID18289CUBUFF);
  lastTouchDist = dist;
}

});

UUID18289CANVAS.addEventListener('touchend', (e) => {
  if (e.touches.length < 2) lastTouchDist = null;
  if (e.touches.length === 0) {lastTouchX = null;is2Press=0;}
  
  
});
let isDragging = false;
let lastMouseX = 0;

UUID18289CANVAS.addEventListener('mousedown', (e) => {
  isDragging = true;
  lastMouseX = e.clientX;
});

UUID18289CANVAS.addEventListener('mouseup', (e) => {
  isDragging = false;
});

UUID18289CANVAS.addEventListener('mouseleave', (e) => {
  isDragging = false;
});

UUID18289CANVAS.addEventListener('mousemove', (e) => {
  if (!isDragging || !UUID18289OB) return;

  const deltaPx = lastMouseX - e.clientX;
  const deltaScroll = deltaPx / UUID18289CANVAS.width * clamp(UUID18289_SCALEX, 0, 20);

  UUID18289_SCROLLX += deltaScroll;

  const maxScroll = (UUID18289OB.length - UUID18289OB.length / UUID18289_SCALEX) / UUID18289OB.length;
  UUID18289_SCROLLX = clamp(UUID18289_SCROLLX, 0, maxScroll * UUID18289_SCALEX);

  drawUUID18289WF(UUID18289CUBUFF);
  lastMouseX = e.clientX;
});

function UUID18289GETTOUCHDIST(e) {
  const [t1, t2] = e.touches;
  const dx = t2.clientX - t1.clientX;
  const dy = t2.clientY - t1.clientY;
  return Math.hypot(dx, dy);
}

function UUID18289GETMIDTOUCH(e) {
  const [t1, t2] = e.touches;
  return (t1.clientX + t2.clientX) / 2;
}

function drawUUID18289WF(buffer) {
  if (!buffer) return;
  UUID18289CTX.clearRect(0, 0, UUID18289CANVAS.width, UUID18289CANVAS.height);
  const data = buffer.getChannelData(0);
  const samplesPerPixel = buffer.length / UUID18289CANVAS.width / UUID18289_SCALEX;
  const sampleOffset = UUID18289_SCROLLX * samplesPerPixel * UUID18289CANVAS.width;
  const startSample = Math.floor(sampleOffset);
  const endSample = Math.min(buffer.length, startSample + Math.floor(UUID18289CANVAS.width * samplesPerPixel));
  const amp = UUID18289CANVAS.height / 2;

  UUID18289CTX.beginPath();
  for (let i = 0; i < UUID18289CANVAS.width; i++) {
    const sampleIndex = startSample + Math.floor(i * samplesPerPixel);
    if (sampleIndex >= buffer.length) break;
    let min = 1.0, max = -1.0;
    const step = Math.ceil(samplesPerPixel);
    for (let j = 0; j < step; j++) {
      const idx = sampleIndex + j;
      if (idx >= buffer.length) break;
      const v = data[idx];
      if (v < min) min = v;
      if (v > max) max = v;
    }
    UUID18289CTX.moveTo(i, (1 + min) * amp);
    UUID18289CTX.lineTo(i, (1 + max) * amp);
  }
  UUID18289CTX.strokeStyle = "#fff";
  UUID18289CTX.stroke();

  if (UUID18289SELECTION && UUID18289SELECTION.x1 !== null && UUID18289SELECTION.x2 === null) {
    const x = (UUID18289SELECTION.x1 - startSample) / samplesPerPixel;
    UUID18289CTX.beginPath();
    UUID18289CTX.arc(clamp(x, 0, UUID18289CANVAS.width), UUID18289CANVAS.height / 2, 5, 0, 2 * Math.PI);
    UUID18289CTX.fillStyle = "blue";
    UUID18289CTX.fill();
  }

  if (UUID18289SELECTION && UUID18289SELECTION.x1 !== null && UUID18289SELECTION.x2 !== null) {
    let x1 = (UUID18289SELECTION.x1 - sampleOffset) / samplesPerPixel;
let x2 = (UUID18289SELECTION.x2 - sampleOffset) / samplesPerPixel;

    if (x2 < x1) [x1, x2] = [x2, x1];
    x1 = clamp(x1, 0, UUID18289CANVAS.width);
    x2 = clamp(x2, 0, UUID18289CANVAS.width);
    UUID18289CTX.fillStyle = "rgba(0, 123, 255, 0.4)";
    UUID18289CTX.fillRect(x1, 0, x2 - x1, UUID18289CANVAS.height);
  }
}

function applyVolume() {
  if (!UUID18289OB || !UUID18289SELECTION || UUID18289SELECTION.x2 === null) return;
  saveUndo();
  const volume = parseFloat(UUID18289VOLUMESLIDER.value);
  const newBuffer = audioUUID18289CTX.createBuffer(UUID18289CUBUFF.numberOfChannels, UUID18289CUBUFF.length, UUID18289CUBUFF.sampleRate);
  
  const startSample = Math.floor(UUID18289SELECTION.x1);
  const endSample = Math.floor(UUID18289SELECTION.x2);

  for (let ch = 0; ch < UUID18289CUBUFF.numberOfChannels; ch++) {
    const input = UUID18289CUBUFF.getChannelData(ch);
    const output = newBuffer.getChannelData(ch);
    for (let i = 0; i < input.length; i++) {
      output[i] = (i >= startSample && i <= endSample) ? input[i] * volume : input[i];
    }
  }
  UUID18289CUBUFF = newBuffer;
 UUID18289VOLUMESLIDER.value=1
 volumeValue.textContent = parseFloat(UUID18289VOLUMESLIDER.value).toFixed(2);
}

function UUID18289PLAYBUFFER(buffer) {
  const blob = bufferToWavBlob(buffer);
  if (UUID18289AUDIOPLAYER.src) URL.revokeObjectURL(UUID18289AUDIOPLAYER.src);
  UUID18289AUDIOPLAYER.src = URL.createObjectURL(blob);
  UUID18289AUDIOPLAYER.play();
}

function bufferToWavBlob(buffer) {
  const interleaved = interleave(buffer);
  const wav = encodeWav(interleaved, buffer.sampleRate, buffer.numberOfChannels);
  return new Blob([wav], { type: "audio/wav" });
}

function interleave(buffer) {
  const length = buffer.length * buffer.numberOfChannels;
  const result = new Float32Array(length);
  for (let i = 0; i < buffer.length; i++) {
    for (let ch = 0; ch < buffer.numberOfChannels; ch++) {
      result[i * buffer.numberOfChannels + ch] = buffer.getChannelData(ch)[i];
    }
  }
  return result;
}

function encodeWav(samples, sampleRate, numChannels) {
  const buffer = new ArrayBuffer(44 + samples.length * 2);
  const view = new DataView(buffer);
  const writeStr = (v, o, s) => { for (let i = 0; i < s.length; i++) v.setUint8(o + i, s.charCodeAt(i)); };
  const floatTo16 = (out, off, input) => {
    for (let i = 0; i < input.length; i++) {
      const s = Math.max(-1, Math.min(1, input[i]));
      out.setInt16(off + i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    }
  };

  writeStr(view, 0, "RIFF");
  view.setUint32(4, 36 + samples.length * 2, true);
  writeStr(view, 8, "WAVE");
  writeStr(view, 12, "fmt ");
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true);
  view.setUint16(22, numChannels, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * numChannels * 2, true);
  view.setUint16(32, numChannels * 2, true);
  view.setUint16(34, 16, true);
  writeStr(view, 36, "data");
  view.setUint32(40, samples.length * 2, true);
  floatTo16(view, 44, samples);
  return view;
}
</script>






 
<style>
#waveInputsContainer {
  margin: 0;
  width: 100vw;
  overflow-x: scroll;
  overflow-y: hidden;
  position: relative;
  height: 30px;
  display: flex;
  flex-direction: row;
  align-items: center;
  gap: 5px;
}
   
  .wave-input{
  	width:25px;
  }
  .keyboard {
    position: relative;
     
    overflow-x: scroll;
    width: 100%;
    max-width: 1050px;
    height: 203px;
    background:#5B5B5B;
    zoom:0.8
  }
  .key {
    position: absolute;
    font-size: 30px;
    display:flex;
    justify-content: center;
    align-items:end ;
    width: 50px;
    height: 200px;
    border: 1px solid #000;
    background-color: #FFFFFF;
  }
  .key:active{
    transform: translate(0,-5px);
    animation: 0.5s blued ;
  }
  @keyframes blued{
    0%{
      background:#898989
    }
    100%{
    }
  }
  .black-key {
    background-color: #000;
    width:35px;
    height: 100px;
    margin-top: -10px;
    margin: 0;
    z-index: 1;
  }
  .active {
    background-color: #4CCDF0;
  }
</style>
</head>
<h2> Whistle to Notes</h2>
<details>
	
<style>
 
#spectrogram {
  border: 1px solid #333;
  background:#000000;
  display: block;
  position: relative;
  left:50vw; 
  transform: translate(-50%,0) ;
  width: 300px;
  height: 300px;
}
.controls {
  display: flex;
  align-items: center;
  gap: 10px;
  flex-wrap: wrap;
}
.sens-wrap {
  display: flex;
  align-items: center;
  gap: 8px;
}
#volColor {
  width: 18px;
  height: 18px;
  border: 1px solid #333;
  border-radius: 3px;
  display: inline-block;
}
#sensDb {
  width: 72px;
}
</style>
 
<div class="controls">
  <button id="btnRec2">Record</button>
  <button id="btnStop2" disabled>Stop</button>
  <button id="btnPlay2">PlayGeneratedNotes</button>
  <button id="btnExport2">ExportMM3</button>
  <button id="btnExport3">ExportJSON</button>
  <input type="file" id="fileInput" accept="audio/*">
  <div class="sens-wrap">
    <label for="sensDb">Sensitivity MIN</label>
    <input type="number" id="sensDb" step="1" value="70" min="1000" max="-125">
    <div id="volColor" title="Sensitivity Color"></div>
  </div>
  <br>
</div>
<br>
<canvas id="spectrogram"></canvas>
<br>
  	<label for="STABLE_N">Stable N</label>
  	<input type="number" id="STABLE_N" step="1" value="2" oninput="if(!isNaN(STABLE_N)){STABLE_N=this.value; }"><br>
  	<label for="SILENCE_N">Silence N</label>
  	<input type="number" id="SILENCE_N" step="1" value="3" oninput="if(!isNaN(SILENCE_N)){SILENCE_N=this.value; }"><br>
  	<label for="MIN_NOTE_MS">Min Note MS</label>
  	<input type="number" id="MIN_NOTE_MS" step="1" value="6" oninput="if(!isNaN(MIN_NOTE_MS)){MIN_NOTE_MS=this.value; }"><br>
  	<label for="CHANGE_HOLD_MS">Change Hold MS</label>
  	<input type="number" id="CHANGE_HOLD_MS" step="1" value="5" oninput="if(!isNaN(CHANGE_HOLD_MS)){CHANGE_HOLD_MS=this.value; }"><br>
 <label for="semitoneShift">Semitone Shift</label>
<input type="number" id="semitoneShift" step="0.5" value="-12">

<script>
const audioctx24 = new (window.AudioContext || window.webkitAudioContext)()
let analyser, mediaSource, isRecording3 = false, startTs = 0
let playing = false, playingSources2 = [], timeouts = []
let currentNote = null, currentStart = 0
let stableBuf = [], silenceStreak = 0
let pendingNote = null, pendingSince = 0
var STABLE_N = 2, SILENCE_N = 3, MIN_NOTE_MS = 6, CHANGE_HOLD_MS = 5
const audiobuff2 = [0, 1]
let semitoneShift = -12
document.getElementById('semitoneShift').addEventListener('input', e => {
  const v = parseFloat(e.target.value)
  if (!isNaN(v)) semitoneShift = v
})

const baseFrequencies2 = {
  'c': 261.63, 'c#': 277.18, 'd': 293.66, 'd#': 311.13, 'e': 329.63,
  'f': 349.23, 'f#': 369.99, 'g': 392, 'g#': 415.3, 'a': 440,
  'a#': 466.16, 'h': 493.88
}
const order = ['c','c#','d','d#','e','f','f#','g','g#','a','a#','h']
const octaves = [1,2,3,4,5,6,7]
const bank = buildNoteBank()

var music = { tempo: 1, run: [1], 1: { notes: [], instrument: 'square', nextSection: null, runallnotes: 1 } }

const canvas2 = document.getElementById("spectrogram")
const ctx2 = canvas2.getContext("2d")
let sensitivityDb = parseFloat(document.getElementById('sensDb').value) || -50
 
const scale = 1
canvas2.width = canvas2.clientWidth * scale;
canvas2.height = canvas2.clientHeight * scale;
ctx2.scale(scale, scale);
 

const volDiv = document.getElementById('volColor')

function dbToColor(db) {
  const t = Math.max(0, Math.min(1, db / 100))
  const hue = Math.round((1 - t) * 120)
  return `hsl(${hue},100%,50%)`
}
function updateSensitivityColor() {
  volDiv.style.backgroundColor = dbToColor(sensitivityDb)
}
updateSensitivityColor()

document.getElementById('sensDb').addEventListener('input', e => {
  const v = parseFloat(e.target.value)
  if (isFinite(v)) {
    sensitivityDb = v
    updateSensitivityColor()
  }
})
function steps(value, step) {
  return ((value % step) + step) % step
}

function clamp(value, min, max) {
  return Math.min(Math.max(value, min), max)
}

function buildNoteBank() {
  const rows = []
  for (const o of octaves) {
    for (const n of order) {
      const f = baseFrequencies2[n] * Math.pow(2, o - 4)
      rows.push({ name: n, oct: o, f })
    }
  }
  rows.sort((a, b) => a.f - b.f)
  for (let i = 0; i < rows.length; i++) {
    const prev = rows[i - 1]?.f || rows[i].f / Math.pow(2, 1 / 12)
    const next = rows[i + 1]?.f || rows[i].f * Math.pow(2, 1 / 12)
    rows[i].lo = (prev + rows[i].f) / 2
    rows[i].hi = (rows[i].f + next) / 2
  }
  return rows
}

function quantize(freq) {
  for (const r of bank) {
    const tolerance = r.f * 0.006 
    if (freq >= r.lo + tolerance && freq < r.hi - tolerance) return r
  }
  return null
}


async function initMic() {
	try {
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
  mediaSource = audioctx24.createMediaStreamSource(stream)
  analyser = audioctx24.createAnalyser()
  analyser.fftSize = 1024
  mediaSource.connect(analyser)
	}catch (e){
		POPUP(innerWidth/2-150, innerHeight/2-100 + window.scrollY
     ,"Microphone Access Error",
    		"<text style='color:black'>You must open FruityBox App and allow microphone access.</text>",
    		"#00afdf"
 	);
	}
}
function detectPitch() {
  const N = analyser.fftSize
  const buf = new Float32Array(N)
  analyser.getFloatTimeDomainData(buf)
  let rms = 0
  for (let i = 0; i < N; i++) rms += buf[i] * buf[i]
  rms = Math.sqrt(rms / N)
  let db = 20 * Math.log10(rms + 1e-12)
  db = Math.max(0, Math.min(100, db + 100))
  if (db < sensitivityDb) return { freq: null, clarity: 0, db }

  let minLag = Math.floor(audioctx24.sampleRate / 2000)
  let maxLag = Math.floor(audioctx24.sampleRate / 150)
  let bestLag = -1, bestCorr = 0
  let sumSq = 0
  for (let i = 0; i < N; i++) sumSq += buf[i] * buf[i]
  for (let lag = minLag; lag <= maxLag; lag++) {
    let corr = 0, energy = 0
    for (let i = 0; i < N - lag; i++) {
      corr += buf[i] * buf[i + lag]
      energy += buf[i + lag] * buf[i + lag]
    }
    const norm = corr / Math.sqrt(sumSq * energy || 1)
    if (norm > bestCorr) { bestCorr = norm; bestLag = lag }
  }
  if (bestLag < 0 || bestCorr < 0.6) return { freq: null, clarity: bestCorr, db }

  const c1 = xcorrAt(buf, bestLag - 1), c2 = xcorrAt(buf, bestLag), c3 = xcorrAt(buf, bestLag + 1)
  const shift = (c3 - c1) / (2 * (2 * c2 - c1 - c3) || 1)
  const refinedLag = bestLag + shift
  const freq = audioctx24.sampleRate / refinedLag
  return { freq, clarity: bestCorr, db }
}

function xcorrAt(buf, lag) {
  let N = buf.length, c = 0, ss1 = 0, ss2 = 0
  for (let i = 0; i < N - lag; i++) {
    c += buf[i] * buf[i + lag]
    ss1 += buf[i] * buf[i]
    ss2 += buf[i + lag] * buf[i + lag]
  }
  return c / Math.sqrt(ss1 * ss2 || 1)
}

 

let scrollSpeed = 5
let frameDuration = 1000 / 60;
let activeLabels = []
function pushNote(noteObj) {
  if (!noteObj) return
  if (noteObj.dur < MIN_NOTE_MS) return
  const shiftedF = noteObj.f * Math.pow(2, semitoneShift / 12)
  music[1].notes.push([shiftedF, noteObj.start - startTs, noteObj.dur, 0.5, 1])
  const label = quantize(shiftedF)
  if (label) {
    activeLabels.push({
      text: label.name + label.oct,
      freq: noteObj.f / Math.pow(2, semitoneShift / 12) ,
      ticks: 30
    })
  }
}

function drawSpectrogram() {
  if (!analyser) return
  const bufferLength = analyser.frequencyBinCount
  const data = new Uint8Array(bufferLength)
  analyser.getByteFrequencyData(data)
  const h = canvas2.height, w = canvas2.width
  const scroll = scrollSpeed
  const imgData = ctx2.getImageData(scroll, 0, w - scroll, h)
  ctx2.putImageData(imgData, 0, 0)
  const sr = audioctx24.sampleRate
  const fMin = 300, fMax = 3000
  for (let y = 0; y < h; y++) {
    const frac = y / h
    const f = fMin + (1 - frac) * (fMax - fMin)
    const idx = Math.round(f * bufferLength / (sr / 2))
    if (idx >= 0 && idx < bufferLength) {
      const val = data[idx]
      ctx2.fillStyle = `hsl(${240 - val * 240 / 255},100%,50%)`
      ctx2.fillRect(w - scroll - 30, y, scroll, 1) 
    }
  }
  const barW = 30
  ctx2.fillStyle = "black"
  ctx2.fillRect(w - barW, 0, barW, h)
  ctx2.font = "14px sans-serif"
  ctx2.textAlign = "center"
  ctx2.textBaseline = "middle"
  activeLabels.forEach(l => {
    const alpha = (l.ticks / 30) ** 2
    const frac = (l.freq - fMin) / (fMax - fMin)
    const y = (1 - frac) * h
    ctx2.fillStyle = `rgba(255,255,255,${alpha})`
    ctx2.fillText(l.text, w - barW / 2, y)
    l.ticks--
  })
  activeLabels = activeLabels.filter(l => l.ticks > 0)
}



let lastDrawnNote = null

function loop() {
  if (isRecording3) {
    drawSpectrogram()

    const { freq, db } = detectPitch()
let q = null
if (freq && db >= sensitivityDb) {
  const shiftedFreq = freq * Math.pow(2, semitoneShift / 12)
  q = quantize(shiftedFreq)
}

    if (q) {
      stableBuf.push(q)
      if (stableBuf.length > STABLE_N) stableBuf.shift()
      const same = stableBuf.every(x => x && x.name === stableBuf[0].name && x.oct === stableBuf[0].oct)
      if (!currentNote && same) {
        currentNote = { name: q.name, oct: q.oct, f: q.f }
        currentStart = performance.now()
        silenceStreak = 0
        pendingNote = null
      } else if (currentNote && (currentNote.name !== q.name || currentNote.oct !== q.oct) && same) {
        if (!pendingNote) {
          pendingNote = { name: q.name, oct: q.oct, f: q.f }
          pendingSince = performance.now()
        } else if (performance.now() - pendingSince > CHANGE_HOLD_MS) {
          const now = performance.now()
          pushNote({ f: currentNote.f, start: currentStart, dur: now - currentStart })
          currentNote = pendingNote
          currentStart = now
          pendingNote = null
        }
      } else {
        pendingNote = null
        silenceStreak = 0
      }
    } else {
      stableBuf = []
      pendingNote = null
      silenceStreak++
      if (currentNote && silenceStreak >= SILENCE_N) {
        const now = performance.now()
        pushNote({ f: currentNote.f, start: currentStart, dur: now - currentStart })
        currentNote = null
      }
    }
  }
  if (!loopRunning) return;
  
  setTimeout(function(){ loop() }, frameDuration);
}
let loopRunning = false;

document.getElementById('btnRec2').onclick = async () => {
  await audioctx24.resume()
  await initMic()
  isRecording3 = true
  music[1].notes = []
  currentNote = null
  startTs = performance.now()
  stableBuf = []
  silenceStreak = 0
  pendingNote = null
  ctx2.clearRect(0, 0, canvas2.width, canvas2.height)
  document.getElementById('btnRec2').disabled = true
  document.getElementById('btnStop2').disabled = false
  if (!loopRunning) {
	loopRunning = true
	loop()
}
}

document.getElementById('btnStop2').onclick = () => {
	 
	   startTs = 0
  isRecording3 = false
  if (currentNote) {
    const now = performance.now()
    pushNote({ f: currentNote.f, start: currentStart, dur: now - currentStart })
    currentNote = null
  }
  document.getElementById('btnRec2').disabled = false
  document.getElementById('btnStop2').disabled = true
}

document.getElementById('btnExport2').onclick = () => {
  const blob = new Blob([JSON.stringify(music)], { type: 'application/octet-stream' })
  const url = URL.createObjectURL(blob)
  const a = document.createElement('a')
  a.href = url
  a.download = 'music.mm3'
  a.click()
  URL.revokeObjectURL(url)
  if (location.href.startsWith("file:///")) {
	NativeJava.DownloadText(JSON.stringify(music), "music.mm3");
}
}
function convertToFruityBox(mm3) {
  		const notes = mm3["1"].notes;
  		notes.sort((a, b) => a[1] - b[1]);
  		const tempo = parseFloat(document.getElementById("tempoData").value)||200 ;
  		const ticksPerBeat = 8;
  		const beatsPerBar = 8;
  		const ticksPerBar = ticksPerBeat * beatsPerBar;
  		const msPerTick = 60000 / tempo / ticksPerBeat;
  		const channels = [];
  		function createEmptyChannel(numPatterns) {
  const patterns = Array.from({ length: numPatterns }, () => ({ notes: [] }));
  const sequence = [...Array(numPatterns).keys()];
return {
	type: "pitch",
	name: "triangle",
	instruments: [{
		type: "chip",
		volume: 0,
		eqFilter: [],
		eqFilterType: false,
		eqSimpleCut: 10,
		eqSimplePeak: 0,
		eqSubFilters0: [],
		effects: [],
		fadeInSeconds: 0,
		fadeOutTicks: 48,
		wave: "triangle",
		envelopes: []
	}],
	patterns: patterns,
	sequence: sequence,
	octaveScrollBar: 0
};
}
function hasOverlap(existingNotes, startTick, endTick) {
  			return existingNotes.some(note => {
  				const nStart = note.points[0].tick;
  				const nEnd = note.points[1].tick;
  				return (startTick < nEnd && endTick > nStart);
});
}
let maxEndTick = 0;
for (const [freq, startMs, lenMs] of notes) {
	let msLEg = 500;
if (document.getElementById("TypeSelect").value == "A")  {
	msLEg = parseInt(lenMs / 6)
}else if (document.getElementById("TypeSelect").value == "B") {
	msLEg = parseInt(lenMs / 8)
}else if ( !isNaN(document.getElementById("TypeSelect").value) ) {
	msLEg = parseInt(document.getElementById("TypeSelect").value)
}
const clippedLenMs = Math.max(40, msLEg);
const absEndTick = Math.round((startMs + clippedLenMs) / msPerTick);
  if (absEndTick > maxEndTick) maxEndTick = absEndTick;
}
const numPatterns = Math.ceil(maxEndTick / ticksPerBar)+1;
  		for (const [freq, startMs, lenMs] of notes) {
  			const absStartTick = Math.round(startMs / msPerTick);
let msLEg=500;
if (document.getElementById("TypeSelect").value == "A") {
	msLEg = parseInt(lenMs / 6)
} else if (document.getElementById("TypeSelect").value == "B") {
	msLEg = parseInt(lenMs / 8)
} else if (!isNaN(document.getElementById("TypeSelect").value)) {
	msLEg = parseInt(document.getElementById("TypeSelect").value)
}
const clippedLenMs = Math.max(40, msLEg );
const absEndTick = Math.round((startMs + clippedLenMs) / msPerTick);
  			const patternIndex = Math.floor(absStartTick / ticksPerBar);
  			const startTick = absStartTick % ticksPerBar;
  			let endTick = absEndTick % ticksPerBar;
if (endTick <= startTick) {
	endTick = startTick + 1;
	if (endTick > ticksPerBar) endTick = ticksPerBar; 
}
const pitch = freqToPitchIndex(freq);
 if (pitch === null) continue;
  			let placed = false;
  			for (let c = 0; c <= channels.length; c++) {
  				if (channels[c] === undefined) channels[c] = createEmptyChannel(numPatterns);
  				const pattern = channels[c].patterns[patternIndex];
  				if (!hasOverlap(pattern.notes, startTick, endTick)) {
  					pattern.notes.push({
  						pitches: [pitch],
  						points: [
  							{ tick: startTick, pitchBend: 0, volume: 100, forMod: false },
  							{ tick: endTick, pitchBend: 0, volume: 100, forMod: false }
  						],
  						continuesLastPattern: false
  					});
  					placed = true;
  					break;
  				}
  			}
if (!placed) {
	const newChan = createEmptyChannel(numPatterns);
	channels.push(newChan);
	const pattern = newChan.patterns[patternIndex];
	pattern.notes.push({
		pitches: [pitch],
		points: [
			{ tick: startTick, pitchBend: 0, volume: 100, forMod: false },
			{ tick: endTick, pitchBend: 0, volume: 100, forMod: false }
		],
		continuesLastPattern: false
	});
}
}
  		return {
  			name: "FruitySong",
  			format: "FruityBox",
  			version: 5,
  			scale: "Free",
  			key: "C",
  			introBars: 0,
  			loopBars: 2,
  			beatsPerBar,
  			ticksPerBeat,
  			beatsPerMinute: tempo,
  			reverb: 0,
  			masterGain: 1,
  			compressionThreshold: 1,
  			limitThreshold: 1,
  			limitDecay: 4,
  			limitRise: 4000,
  			limitRatio: 1,
  			compressionRatio: 1,
  			layeredInstruments: false,
  			patternInstruments: false,
  			channels
  		};
  	}
  	
  	function freqToPitchIndex(freq) {
  		const midi = 69 + 12 * Math.log2(freq / 440);
  		const pitch = Math.round(midi - 12);
  		if (pitch < 0 || pitch > 95*2) return null;
  		return pitch;
  	}
  	
document.getElementById('btnExport3').onclick = () => {
	let fruitybox=convertToFruityBox(music)
	let	jsonfull=JSON.stringify(fruitybox, null, 2)
	const blob = new Blob([jsonfull], { type: 'application/octet-stream' })
	const url = URL.createObjectURL(blob)
	const a = document.createElement('a')
	a.href = url
	a.download = 'fruit.json'
	a.click()
	URL.revokeObjectURL(url)
	if (location.href.startsWith("file:///")) {
		NativeJava.DownloadText(jsonfull, "fruit.json");
	}
}

document.getElementById('btnPlay2').onclick = () => playMusic1(music)

 
async function playTone3(audioCTX2, frequency, duration, volume, customInstrument, volumeEasing=1) {
	return new Promise(resolve => {
		 
		const sampleRate = audioCTX2.sampleRate;
		const frameCount = sampleRate * (((duration+500) / 1000));
		const buffer = audioCTX2.createBuffer(1, frameCount, sampleRate);
		const data = buffer.getChannelData(0);
		const waveformLength = audiobuff.length;
		for (let i = 0; i < frameCount; i++) {
			let time = i / sampleRate;
			let amplitude = volume;
			if (volumeEasing === 1) {
				amplitude *= Math.exp(-5 * time / ((duration+500) / 1000)) ;
			} else if (volumeEasing > 1) {
				amplitude *= 1 - Math.exp(-5 * time / (((duration+500) / 1000) * volumeEasing));
			}
			let wavePosition = (i * frequency * waveformLength / sampleRate) % waveformLength;
			let index = Math.floor(wavePosition);
			let nextIndex = (index + 1) % waveformLength;
			let frac = wavePosition - index;
			let sample = audiobuff[index] * (1 - frac) + audiobuff[nextIndex] * frac;
			data[i] = amplitude * sample;
		}
		const source = audioCTX2.createBufferSource();
		source.buffer = buffer;
		source.connect(audioCTX2.destination);
		playingSources.push(source);
		source.start();
		const keyId = Object.keys(frequencies).find(k => Math.abs(frequencies[k] - frequency ) < 1);
		if (keyId) document.getElementById(keyId)?.classList.add('active');
		setTimeout(function() {
			if (keyId) document.getElementById(keyId)?.classList.remove('active');
		}, 200)
		source.onended = () => {
			resolve();
		};
	});
}
function playMusic1(score) {
  timeouts.forEach(t => clearTimeout(t))
  timeouts = []
  playingSources2.forEach(s => { try { s.stop() } catch (e) {} })
  playingSources2 = []
  if (playing) { playing = false; return }
  playing = true
  const notes = score[1].notes.slice()
  const tempo = score[1].tempo || score.tempo || 1
  for (const n of notes) {
    const [hz, offset, dur, vol] = n
    const t = setTimeout(() => {
      if (!playing) return
      playTone3(audioctx24, hz, dur / tempo, vol,0,1).then(() => {})
    }, offset / tempo)
    timeouts.push(t)
  }
  if (notes.length) {
    const last = notes[notes.length - 1]
    const total = (last[1] + last[2]) / tempo
    const endT = setTimeout(() => { playing = false }, total + 50)
    timeouts.push(endT)
  } else {
    playing = false
  }
}

document.getElementById('fileInput').addEventListener('change', async e => {
  const file = e.target.files[0]
  if (!file) return
  try {
    const arrayBuffer = await file.arrayBuffer()
    const audioBuf = await audioctx24.decodeAudioData(arrayBuffer)
    analyser = audioctx24.createAnalyser()
    analyser.fftSize = 1024
    const src = audioctx24.createBufferSource()
    src.buffer = audioBuf
    src.connect(analyser)
    const proc = audioctx24.createScriptProcessor(1024, 1, 1)
    src.connect(proc)
    proc.connect(audioctx24.destination)
    startTs = performance.now()
    stableBuf = []
    currentNote = null
    proc.onaudioprocess = () => {
      const { freq, db } = detectPitch()
      let q = null
if (freq && db >= sensitivityDb) {
  const shiftedFreq = freq * Math.pow(2, semitoneShift / 12)
  q = quantize(shiftedFreq)
}

      if (q) {
        stableBuf.push(q)
        if (stableBuf.length > STABLE_N) stableBuf.shift()
        const same = stableBuf.every(x => x && x.name === stableBuf[0].name && x.oct === stableBuf[0].oct)
        if (!currentNote && same) {
          currentNote = { name: q.name, oct: q.oct, f: q.f }
          currentStart = performance.now()
        } else if (currentNote && (currentNote.name !== q.name || currentNote.oct !== q.oct) && same) {
          const now = performance.now()
          music[1].notes.push([currentNote.f, currentStart - startTs, now - currentStart, 0.5, 1])
          currentNote = { name: q.name, oct: q.oct, f: q.f }
          currentStart = now
        }
      } else {
        if (currentNote) {
          silenceStreak++
          if (silenceStreak >= SILENCE_N) {
            const now = performance.now()
            music[1].notes.push([currentNote.f, currentStart - startTs, now - currentStart, 0.5, 1])
            currentNote = null
            silenceStreak = 0
          }
        }
      }
    }
    src.start()
  } catch (err) {}
})
let togglekeyboardpos=0
</script>
</details>


<move id="main1">
	<move id="keyboard">
<h2>Melody Maker</h2>
 <details>
 	
 	
  <div style="color:var(--primary-text, black); user-select: none;  background:var(--editor-background, black); min-height:600px">
    duration:
<select id="durationL">
 <option value="100">100</option>
  <option value="200">200</option>
  <option value="500">500</option>
  <option value="1000">1000</option>
  <option value="1500">1500</option>
  <option value="2000">2000</option>
  <option value="2500">2500</option>
  <option value="3000">3000</option>
</select>
<br>
<button id="startRecordingButton">start recording</button>
<button onclick="
togglekeyboardpos = !togglekeyboardpos;
const keyboard = document.getElementById('keyboard');
if (togglekeyboardpos) document.getElementById('main2').appendChild(keyboard);
else document.getElementById('main1').appendChild(keyboard);
">Toggle Pos</button>
<button id="stopRecordingButton" disabled>stop recording</button>
Import music <input type="file" id="ImportMusic" accept=".mm3">
<button onclick="playMusic(music)">play recorded music</button>
<button onclick="recordreset()">reset record</button>
<button onclick="saveAsBlob()">SAVE as mm3</button>
<button onclick="removefrombuttonstext()">notext</button>
  Octaves: <input type="number" id="octaves" value="3" min="1" max="7">
  Start Octave: <input type="number" id="startOctave" value="3" min="0" max="8">
  
  <button onclick="generateKeyboard()">Build Keyboard</button>
  <br>
<label><input type="checkbox" id="metronomeToggle"> Hear Metronome</label>
Metronome Time (ms): <input type="number" style="width:60px" id="metronomeTime" value="4000" min="100">

<label>Tempo (BPM): <input type="number" id="bpmInput" value="120" min="1" max="1000"></label>
<input type="checkbox" id="beepboxpiano"> Use Beepbox Piano </label>
<select  id="MetronomeMode" >
	<option value="0">Hear Metronome After Pattern</option>
	<option value="1">Hear Metronome After 1 Bar</option>
</select> 
<button onclick="calculateMetronome()">Calculate Metronome Time</button>

  <br><br>
  Keyboard Buffer 
  <form id="waveInputsContainer">
  	<input type="number" class="wave-input" onkeydown="handleWaveInput(event)"></form>
<div class="keyboard" id="keyboardContainer">
</div>
 
  </div>
<script>
let metronomeInterval = null;
function calculateMetronome() {
  const bpm = parseFloat(document.getElementById("bpmInput").value);
  const beatsPerBar = 8;
  if (isNaN(bpm) || bpm <= 0 || isNaN(beatsPerBar) || beatsPerBar <= 0) {
    alert("Please enter valid BPM and beats per bar.");
    return;
  }
  let beatDuration = 60000 / bpm*beatsPerBar;
  if(document.getElementById("MetronomeMode").value==1){
  	beatDuration = 60000 / bpm;
  }
  document.getElementById("metronomeTime").value = Math.round(beatDuration);
}

function playMetronomeClick() {
  const osc = audioCTX2.createOscillator();
  const gain = audioCTX2.createGain();
  osc.frequency.value = 1000;
  gain.gain.value = 0.1;

  osc.connect(gain);
  gain.connect(audioCTX2.destination);

  osc.start();
  osc.stop(audioCTX2.currentTime + 0.05);
}

function startMetronome() {
  const time = parseInt(document.getElementById("metronomeTime").value);
  if (isNaN(time) || time < 50) return;

  metronomeInterval = setInterval(() => {
    playMetronomeClick();
  }, time);
}

function stopMetronome() {
  if (metronomeInterval) {
    clearInterval(metronomeInterval);
    metronomeInterval = null;
  }
}

 

function blobToBase642(blob) {
	return new Promise((resolve, reject) => {
		const reader = new FileReader();
		reader.onload = () => {
			const base64data = reader.result.split(',')[1];
			resolve(base64data);
		};
		reader.onerror = reject;
		reader.readAsDataURL(blob);
	});
}

let isPlaying=false;
let playingSources=[];
let activeTimeouts=[]
function setupKeyEvents() {
  const keys = document.querySelectorAll('.key');
  keys.forEach(key => {
    key.onmousedown = () => {
      key.classList.add('active');
      const id = key.id;
      const frequency = frequencies[id];
      if (frequency) {
        playSound(frequency);
        if (isRecording) {
          recordedNotes.push([frequency, performance.now() - startTime, parseFloat(document.getElementById('durationL').value), 0.5, 1]);
        }
      }
    };
    key.onmouseup = key.onmouseleave = () => {
      key.classList.remove('active');
    };
  });
}
function generateKeyboard() {
  const container = document.getElementById("keyboardContainer");
  container.innerHTML = '';
  const whiteNotes = ['c', 'd', 'e', 'f', 'g', 'a', 'h'];
  const blackNotes = ['c#', 'd#', null, 'f#', 'g#', 'a#', null];
  const baseFrequencies = {
    'c': 261.63,
    'c#': 277.18,
    'd': 293.66,
    'd#': 311.13,
    'e': 329.63,
    'f': 349.23,
    'f#': 369.99,
    'g': 392.00,
    'g#': 415.30,
    'a': 440.00,
    'a#': 466.16,
    'h': 493.88,
  };
  const octaves = parseInt(document.getElementById("octaves").value);
  const startOctave = parseInt(document.getElementById("startOctave").value);
  let keyIndex = 1;
  let posX = 0;
  for (let octave = startOctave; octave < startOctave + octaves; octave++) {
    for (let i = 0; i < whiteNotes.length; i++) {
      const note = whiteNotes[i];
      const freq = baseFrequencies[note] * Math.pow(2, octave - 4);
      const white = document.createElement("div");
      white.className = "key white-key";
       
      white.id = `key${keyIndex}`;
      white.innerText = note ;
      white.style.left = `${posX}px`;
      white.style.position = 'absolute';
      container.appendChild(white);
      frequencies[`key${keyIndex}`] = freq;
      keyIndex++;
      posX += 50;
    }
  }
  keyIndex = 1;
  posX = 0;
  for (let octave = startOctave; octave < startOctave + octaves; octave++) {
    for (let i = 0; i < blackNotes.length; i++) {
      const black = blackNotes[i];
      if (!black) {
        posX += 50;
        continue;
      }
      const freq = baseFrequencies[black] * Math.pow(2, octave - 4);
      const blackKey = document.createElement("div");
      blackKey.className = "key black-key";
      blackKey.id = `key${keyIndex + 1000}`;
      blackKey.style.left = `${posX + 35}px`;
      blackKey.style.position = 'absolute';
      container.appendChild(blackKey);
      frequencies[`key${keyIndex + 1000}`] = freq;
      keyIndex++;
      posX += 50;
    }
  }
  setupKeyEvents();
}
  const audioCTX2 = new (window.AudioContext || window.webkitAudioContext)();
  const frequencies = {
 
  };
generateKeyboard()
  let startTime = 0;  
  let isRecording = false;
  let recordedNotes = [];
  function recordreset(){
    recordedNotes = [];
    audioCTX2.currentTime = 0;
  }
let audiobuff = [0,0, 0.5 , 0.5,]; 
function handleWaveInput(event) {
  if (event.key === "Enter") {
  	event.preventDefault();
    const newInput = document.createElement("input");
    newInput.type = "number";
    newInput.className = "wave-input";
    newInput.onkeydown = handleWaveInput;
    document.getElementById("waveInputsContainer").appendChild(newInput);
    newInput.focus();
    updateWaveArray();
  }else if ((event.key === "Delete" || event.key === "Backspace") && event.target.value === "") {
	const inputs = document.querySelectorAll(".wave-input");
	if (inputs.length > 1) {
		event.preventDefault();
		event.target.remove();
		updateWaveArray();
	}
}
 else {
    setTimeout(updateWaveArray, 0);
  }
}
function updateWaveArray() {
  audiobuff = Array.from(document.querySelectorAll(".wave-input"))
    .map(inp => parseFloat(inp.value) || 0);
}
function loadWaveInputsFromArray() {
  const container = document.getElementById("waveInputsContainer");
  container.innerHTML = ''; 
  audiobuff.forEach(value => {
    const input = document.createElement("input");
    input.type = "number";
    input.className = "wave-input";
    input.value = value;
    input.onkeydown = handleWaveInput;
    container.appendChild(input);
    
  });
  updateWaveArray();
}
loadWaveInputsFromArray()
function frequencyToPitch(frequency) {
    return Math.round(12 * Math.log2(frequency / 440) + 57);
}


function playSound(frequency) {
 if (document.getElementById("beepboxpiano").checked) {
  let duration = parseFloat(document.getElementById('durationL').value);
  pressPianoKey(  frequencyToPitch(frequency), duration);
 }else{
  const sampleRate = audioCTX2.sampleRate;
  let duration = parseFloat(document.getElementById('durationL').value);
  let volume = 0.5;
  let volumeEasing = 1;
  let frameCount = sampleRate * (duration / 1000);
  let buffer = audioCTX2.createBuffer(1, frameCount, sampleRate);
  let data = buffer.getChannelData(0);
  let waveformLength = audiobuff.length;
  for (let i = 0; i < frameCount; i++) {
    let time = i / sampleRate;
    let amplitude = volume;
    if (volumeEasing === 1) {
      amplitude *= Math.exp(-5 * time / (duration / 1000));
    } else if (volumeEasing > 1) {
      amplitude *= 1 - Math.exp(-5 * time / ((duration / 1000) * volumeEasing));
    }
    let wavePosition = (i * frequency * waveformLength / sampleRate) % waveformLength;
    let index = Math.floor(wavePosition);
    let nextIndex = (index + 1) % waveformLength;
    let frac = wavePosition - index;
    let sample = audiobuff[index] * (1 - frac) + audiobuff[nextIndex] * frac;
    data[i] = amplitude * sample;
  }
  let source = audioCTX2.createBufferSource();
  source.buffer = buffer;
  source.connect(audioCTX2.destination);
  source.start();
 }
}
 
  document.getElementById('startRecordingButton').addEventListener('click', () => {
    isRecording = true;
    startTime = performance.now();
    recordedNotes = [];
if (document.getElementById("metronomeToggle").checked) {
	startMetronome();
} else {
	stopMetronome();
}
    document.getElementById('startRecordingButton').disabled = true;
    document.getElementById('stopRecordingButton').disabled = false;
  });
  document.getElementById('stopRecordingButton').addEventListener('click', () => {
    isRecording = false;
    
    document.getElementById('startRecordingButton').disabled = false;
    document.getElementById('stopRecordingButton').disabled = true;
    music[1].notes = recordedNotes.map(note => {
      const [frequency, startTime, duration, volume, volumeEasing] = note;
      return [frequency, startTime, duration, volume, volumeEasing];
    });
    stopMetronome();
  });
  function saveAsBlob() {
    const blob = new Blob([JSON.stringify(music)], { type: 'application/octet-stream' });

    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = 'music.mm3';
    a.click();
    URL.revokeObjectURL(url);
    
if (location.href.startsWith("file:///")) {
	NativeJava.DownloadText( JSON.stringify(music) , "music.mm3");
}
    
  }
  function removefrombuttonstext() {
    const pianoKeys = document.querySelectorAll('.key');
    pianoKeys.forEach(key => {
      key.innerText = "";
    });
  }
  async function playTone(audioCTX2, frequency, duration, volume, customInstrument, volumeEasing) {
  return new Promise(resolve => {
    const sampleRate = audioCTX2.sampleRate;
    const frameCount = sampleRate * (duration / 1000);
    const buffer = audioCTX2.createBuffer(1, frameCount, sampleRate);
    const data = buffer.getChannelData(0);
    const waveformLength = audiobuff.length;
    for (let i = 0; i < frameCount; i++) {
      let time = i / sampleRate;
      let amplitude = volume;
      if (volumeEasing === 1) {
        amplitude *= Math.exp(-5 * time / (duration / 1000));
      } else if (volumeEasing > 1) {
        amplitude *= 1 - Math.exp(-5 * time / ((duration / 1000) * volumeEasing));
      }
      let wavePosition = (i * frequency * waveformLength / sampleRate) % waveformLength;
      let index = Math.floor(wavePosition);
      let nextIndex = (index + 1) % waveformLength;
      let frac = wavePosition - index;
      let sample = audiobuff[index] * (1 - frac) + audiobuff[nextIndex] * frac;
      data[i] = amplitude * sample;
    }
    const source = audioCTX2.createBufferSource();
    source.buffer = buffer;
    source.connect(audioCTX2.destination);
    playingSources.push(source);
    source.start();
    const keyId = Object.keys(frequencies).find(k => Math.abs(frequencies[k] - frequency) < 1);
if (keyId) document.getElementById(keyId)?.classList.add('active');

setTimeout(function(){
	if (keyId) document.getElementById(keyId)?.classList.remove('active');
},200)

source.onended = () => {
	resolve();
};
  });
}
  async function playSection(audioCTX2, sectionId) {
  const section = music[sectionId];
  const { notes, instrument, nextSection, runallnotes } = section;
  const tempo = section.tempo || music.tempo;

  if (runallnotes) {
    const promises = notes.map(([hz, timeout, length, volume, volumeEasing]) => {
      return new Promise(resolve => {
        const t = setTimeout(() => {
          if (!isPlaying) return resolve();
          playTone(audioCTX2, hz, length / tempo, volume, instrument, volumeEasing).then(resolve);
        }, timeout / tempo);
        activeTimeouts.push(t);
      });
    });
    await Promise.all(promises);
  } else {
    for (const note of notes) {
      if (!isPlaying) break;
      const [hz, timeout, length, volume, volumeEasing] = note;
      await playTone(audioCTX2, hz, length / tempo, volume, instrument, volumeEasing);
      if (!isPlaying) break;
      await new Promise(resolve => {
        const t = setTimeout(() => resolve(), timeout / tempo);
        activeTimeouts.push(t);
      });
    }
  }

  if (nextSection !== null && isPlaying) {
    await playSection(audioCTX2, nextSection);
  }
}

async function playMusic(name) {
  const playButton = document.querySelector('button[onclick^="playMusic"]');
  playingSources.forEach(src => src.stop());
  playingSources = [];
  activeTimeouts.forEach(timeout => clearTimeout(timeout));
  activeTimeouts = [];
  if (isPlaying) {
    isPlaying = false;
    playButton.textContent = 'play recorded music';
    return;
  }
  isPlaying = true;
  playButton.textContent = 'pause recorded music';

  const runSections = name.run;
  for (let sectionId of runSections) {
    if (!isPlaying) break;
    await playSection(audioCTX2, sectionId);
  }

  isPlaying = false;
  playButton.textContent = 'play recorded music';
}


  var music = {
    tempo: 1,  
    run: [1],  
    1: {
      notes: [],
      instrument: 'square',
      nextSection: null,
      runallnotes: 1
    }
  };
document.getElementById("ImportMusic").addEventListener("change", function (event) {
  const file = event.target.files[0];
  if (!file) return;
  const reader = new FileReader();
  reader.onload = function (e) {
    try {
      const importedMusic = JSON.parse(e.target.result);
      if (importedMusic && typeof importedMusic === 'object') {
        music = importedMusic;
        alert("Loaded !");
      } else {
        alert("Error loading");
      }
    } catch (err) {
      alert("Error:  " + err.message);
    }
  };
  reader.readAsText(file);
});

</script>




   <h2>MM3 TO BEEPBOX JSON</h2>
   input mode <select id="TypeSelect">
	<option value="200">250</option>
	<option value="500">500</option>
	<option value="A">defined/6</option>
	<option value="B">defined/8</option>
</select>
  tempo: <input id="tempoData" type="text" value="120">
  <input type="file" id="ConverterBox" accept=".mm3">
  <button id="convertBtn">Convert</button>
  <script>
  
  function blobToBase642(blob) {
	return new Promise((resolve, reject) => {
		const reader = new FileReader();
		reader.onload = () => {
			const base64data = reader.result.split(',')[1];
			resolve(base64data);
		};
		reader.onerror = reject;
		reader.readAsDataURL(blob);
	});
}
  
  	document.getElementById("convertBtn").addEventListener("click", () => {
  		const ConverterBox = document.getElementById("ConverterBox");
  		if (!ConverterBox.files.length) return;
  		
  		const reader = new FileReader();
  		reader.onload = function(e) {
  			const mm3 = JSON.parse(e.target.result);
  			const fruitybox = convertToFruityBox(mm3);
  			let	jsonfull=JSON.stringify(fruitybox, null, 2)
  			const blob = new Blob([jsonfull], { type: "application/json" });
  			const url = URL.createObjectURL(blob);
  			const a = document.createElement("a");
  			a.href = url;
  			a.download = "fruitybox.json";
  			a.click();
  			URL.revokeObjectURL(url);
  			
if (location.href.startsWith("file:///")) {
	NativeJava.DownloadText( jsonfull , "fruitybox.json");
}
  			
  		};
  		reader.readAsText(ConverterBox.files[0]);
  	});
  	 
  	function convertToFruityBox(mm3) {
  		const notes = mm3["1"].notes;
  		notes.sort((a, b) => a[1] - b[1]);
  		const tempo = parseFloat(document.getElementById("tempoData").value)||200 ;
  		const ticksPerBeat = 8;
  		const beatsPerBar = 8;
  		const ticksPerBar = ticksPerBeat * beatsPerBar;
  		const msPerTick = 60000 / tempo / ticksPerBeat;
  		const channels = [];
  		function createEmptyChannel(numPatterns) {
  const patterns = Array.from({ length: numPatterns }, () => ({ notes: [] }));
  const sequence = [...Array(numPatterns).keys()];
return {
	type: "pitch",
	name: "triangle",
	instruments: [{
		type: "chip",
		volume: 0,
		eqFilter: [],
		eqFilterType: false,
		eqSimpleCut: 10,
		eqSimplePeak: 0,
		eqSubFilters0: [],
		effects: [],
		fadeInSeconds: 0,
		fadeOutTicks: 48,
		wave: "triangle",
		envelopes: []
	}],
	patterns: patterns,
	sequence: sequence,
	octaveScrollBar: 0
};
}
function hasOverlap(existingNotes, startTick, endTick) {
  			return existingNotes.some(note => {
  				const nStart = note.points[0].tick;
  				const nEnd = note.points[1].tick;
  				return (startTick < nEnd && endTick > nStart);
});
}
let maxEndTick = 0;
for (const [freq, startMs, lenMs] of notes) {
	let msLEg = 500;
if (document.getElementById("TypeSelect").value == "A")  {
	msLEg = parseInt(lenMs / 6)
}else if (document.getElementById("TypeSelect").value == "B") {
	msLEg = parseInt(lenMs / 8)
}else if ( !isNaN(document.getElementById("TypeSelect").value) ) {
	msLEg = parseInt(document.getElementById("TypeSelect").value)
}
const clippedLenMs = Math.max(40, msLEg);
const absEndTick = Math.round((startMs + clippedLenMs) / msPerTick);
  if (absEndTick > maxEndTick) maxEndTick = absEndTick;
}
const numPatterns = Math.ceil(maxEndTick / ticksPerBar)+1;
  		for (const [freq, startMs, lenMs] of notes) {
  			const absStartTick = Math.round(startMs / msPerTick);
let msLEg=500;
if (document.getElementById("TypeSelect").value == "A") {
	msLEg = parseInt(lenMs / 6)
} else if (document.getElementById("TypeSelect").value == "B") {
	msLEg = parseInt(lenMs / 8)
} else if (!isNaN(document.getElementById("TypeSelect").value)) {
	msLEg = parseInt(document.getElementById("TypeSelect").value)
}
const clippedLenMs = Math.max(40, msLEg );
const absEndTick = Math.round((startMs + clippedLenMs) / msPerTick);
  			const patternIndex = Math.floor(absStartTick / ticksPerBar);
  			const startTick = absStartTick % ticksPerBar;
  			let endTick = absEndTick % ticksPerBar;
if (endTick <= startTick) {
	endTick = startTick + 1;
	if (endTick > ticksPerBar) endTick = ticksPerBar; 
}
const pitch = freqToPitchIndex(freq);
 if (pitch === null) continue;
  			let placed = false;
  			for (let c = 0; c <= channels.length; c++) {
  				if (channels[c] === undefined) channels[c] = createEmptyChannel(numPatterns);
  				const pattern = channels[c].patterns[patternIndex];
  				if (!hasOverlap(pattern.notes, startTick, endTick)) {
  					pattern.notes.push({
  						pitches: [pitch],
  						points: [
  							{ tick: startTick, pitchBend: 0, volume: 100, forMod: false },
  							{ tick: endTick, pitchBend: 0, volume: 100, forMod: false }
  						],
  						continuesLastPattern: false
  					});
  					placed = true;
  					break;
  				}
  			}
if (!placed) {
	const newChan = createEmptyChannel(numPatterns);
	channels.push(newChan);
	const pattern = newChan.patterns[patternIndex];
	pattern.notes.push({
		pitches: [pitch],
		points: [
			{ tick: startTick, pitchBend: 0, volume: 100, forMod: false },
			{ tick: endTick, pitchBend: 0, volume: 100, forMod: false }
		],
		continuesLastPattern: false
	});
}
}
  		



  		return {
  			name: "FruitySong",
  			format: "FruityBox",
  			version: 5,
  			scale: "Free",
  			key: "C",
  			introBars: 0,
  			loopBars: 2,
  			beatsPerBar,
  			ticksPerBeat,
  			beatsPerMinute: tempo,
  			reverb: 0,
  			masterGain: 1,
  			compressionThreshold: 1,
  			limitThreshold: 1,
  			limitDecay: 4,
  			limitRise: 4000,
  			limitRatio: 1,
  			compressionRatio: 1,
  			layeredInstruments: false,
  			patternInstruments: false,
  			channels
  		};
  	}
  	
  	function freqToPitchIndex(freq) {
  		const midi = 69 + 12 * Math.log2(freq / 440);
  		const pitch = Math.round(midi - 12);
  		if (pitch < 0 || pitch > 95*2) return null;
  		return pitch;
  	}
  </script>
  

 
 </details>
	</move>
</move>

 <h2>Custom Themes</h2>
<details>
 
  <div class="menu">
    <label>Theme Name:</label>
    <input id="varname2" type="text">
    <label>Your Css Theme:</label>
    <input id="cssInput" >
    <button id="generateButton2" disabled>Create</button>
  </div>
  <div id="themeList"></div>
  <div></div>
 

<script>
function createStorage(dbName = "myDB", storeName = "store") {
  const dbPromise = new Promise((resolve, reject) => {
    const request = indexedDB.open(dbName, 1);
    request.onupgradeneeded = (event) => {
      const db = event.target.result;
      if (!db.objectStoreNames.contains(storeName)) {
        db.createObjectStore(storeName);
      }
    };
    request.onsuccess = () => {
      resolve(request.result);
    };
    request.onerror = () => {
      reject(request.error);
    };
  });
  async function save(slot, data) {
    const db = await dbPromise;
    return new Promise((resolve, reject) => {
      const tx = db.transaction([storeName], "readwrite");
      const store = tx.objectStore(storeName);
      const req = store.put(data, slot);
      req.onsuccess = () => resolve();
      req.onerror = () => reject(req.error);
    });
  }
 async function remove(slot) {
 	const db = await dbPromise;
  	return new Promise((resolve, reject) => {
  		const tx = db.transaction([storeName], "readwrite");
	  	const store = tx.objectStore(storeName);
  		const req = store.delete(slot);
  		req.onsuccess = () => resolve();
		  req.onerror = () => reject(req.error);
  	});
  }
  function load(slot, callback) {
  dbPromise.then(db => {
    const tx = db.transaction([storeName], "readonly");
    const store = tx.objectStore(storeName);
    const req = store.get(slot);
    req.onsuccess = () => callback(req.result ?? null);
    req.onerror = () => callback(null);
  }).catch(() => callback(null));
}
  return { save, load, remove , dbPromise};
}
THEMESDB=createStorage("Themes","themes")

 
 
function renderFileList2() {
	const list = document.getElementById('themeList');
	list.innerHTML = '';
	Object.keys(CustomThemes).forEach(id => {
		const div = document.createElement('div');
		div.className = 'file-item';
		div.id = `file-${id}`;
		const span = document.createElement('span');
		span.textContent = id;
		const btn1 = document.createElement('button');
  btn1.textContent = 'copy';
		const btn = document.createElement('button');
		btn.textContent = 'X';
		btn.onclick = () => {
			delete CustomThemes[id];
			  THEMESDB.remove(id);
			document.getElementById(`file-${id}`).remove();
		};
		btn1.onclick = () => {
  document.getElementById(`cssInput`).value=CustomThemes[id];
  document.getElementById(`varname2`).value=id;
  };
		div.appendChild(span);
		div.appendChild(btn1);
		div.appendChild(btn);
		list.appendChild(div);
	});
}
document.getElementById('cssInput').addEventListener('input', (event) => {
	if(document.getElementById('cssInput').value!=="" && document.getElementById('varname2').value!=="" ){
	document.getElementById('generateButton2').disabled = false;
	}else{
	document.getElementById('generateButton2').disabled = true;
	}
});
document.getElementById('varname2').addEventListener('input', (event) => {
	if (document.getElementById('cssInput').value !== "" && document.getElementById('varname2').value !== "") {
		document.getElementById('generateButton2').disabled = false;
	} else {
		document.getElementById('generateButton2').disabled = true;
	}
});

 
async function audioFileToBuffer(file) {
  const arrayBuffer = await file.arrayBuffer();
  const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
  const channelData = audioBuffer.getChannelData(0);
  return Array.from(channelData);
}

function blobToBase6422(blob) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => {
      const base64data = reader.result.split(',')[1];
      resolve(base64data);
    };
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
}
document.getElementById('generateButton2').addEventListener('click', async () => {
  const name = document.getElementById('varname2').value;
  const css = document.getElementById('cssInput').value;
  CustomThemes[name] = css;
  await THEMESDB.save(name, css); 
  document.getElementById('varname2').value = '';
  document.getElementById('cssInput').value = '';
  document.getElementById('generateButton2').disabled = true;
  renderFileList2();
  loadFiles2()
});

async function loadFiles2() {
  CustomThemes = {};
  const db = await THEMESDB.dbPromise;
  const tx = db.transaction(["themes"], "readonly");
  const store = tx.objectStore("themes");
  const req = store.openCursor();

  req.onsuccess = (event) => {
    const cursor = event.target.result;
    if (cursor) {
      CustomThemes[cursor.key] = cursor.value;
      cursor.continue();
    } else {
     	updateThemes()
      renderFileList2(); 
    }
  };
}

setTimeout(loadFiles2,800)

</script>
</details>
<br>
 <button onclick='document.location.href="./midiplayer.html";
'>Open MIDI Player</button>
 <button onclick='document.location.href="./sample_extractor.html";
'>Open Sample Extractor</button>
<button onclick="console_profiler123.style.display=console_profiler123.style.display=='block'?'none':'block' ">Debug Console</button>
</div>
<script>
 
const console_profiler123=document.createElement("div")
console_profiler123.id="console-panel"
console_profiler123.style.cssText="position:fixed;bottom:0;left:0;width:250px;height:200px;background:#111;color:#0f0;font:12px monospace;z-index:9999;overflow:auto;display:none;white-space:pre-wrap;user-select:text !important;"
document.body.appendChild(console_profiler123)
 
const origLog=console.log
console.log=function(...args){
 origLog.apply(console,args)
 const msg=args.map(a=>(typeof a==="object"?JSON.stringify(a):a)).join(" ")
 const div=document.createElement("div")
 div.style.color="#0f0"
 div.textContent=msg
 console_profiler123.appendChild(div)
 console_profiler123.scrollTop=console_profiler123.scrollHeight
}


window.addEventListener("error", e => {
 const div = document.createElement("div")
 div.style.color = "red"
 div.textContent = `${e.message} @${e.filename}:${e.lineno}:${e.colno}`
 console_profiler123.appendChild(div)
 console_profiler123.scrollTop = console_profiler123.scrollHeight
})

window.addEventListener("unhandledrejection", e => {
 const div = document.createElement("div")
 div.style.color = "orange"
 div.textContent = `UnhandledPromiseRejection: ${e.reason}`
 console_profiler123.appendChild(div)
 console_profiler123.scrollTop = console_profiler123.scrollHeight
})


function toggleDebug(){
 ttgl34_ui5tyFrtVghyjk_67=ttgl34_ui5tyFrtVghyjk_67==0?1:0
}
</script>